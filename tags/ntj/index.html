<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Ntj</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Ntj</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhantonsson_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhantonsson_2021/>Antonsson 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2020.607449</p><h2 id=one-liner>One-Liner</h2><p><a href=/posts/kbhoral_lexical_retrival/>oral lexical retrieval</a> works better than qualitative narrative analysis to classify dementia; and semantic fluency + Disfluency features chucked on an SVM returns pretty good results.</p><h2 id=novelty>Novelty</h2><p>Tried two different assays of measuring linguistic ability: <a href=/posts/kbhoral_lexical_retrival/>oral lexical retrieval</a> metrics, and qualitative <a href=/posts/kbhdiscourse_features/>discourse features</a> analysis of speech.</p><h2 id=notable-methods>Notable Methods</h2><ul><li><p>Subjects divided into three groups</p><ul><li>Great cog. decline</li><li>Impaired but stable</li><li>Healthy controls</li></ul></li><li><p>Administered <a href=/posts/kbhboston_naming_test/>BNT</a> and <a href=/posts/kbhsemantic_verbal_fluency/>SVF</a> tests as baseline</p><figure><img src=/ox-hugo/2022-06-23_23-23-08_screenshot.png></figure></li></ul><h2 id=key-figs>Key Figs</h2><h3 id=table-3>Table 3</h3><figure><img src=/ox-hugo/2022-06-23_23-02-14_screenshot.png></figure><p>This figure tells us that the percentages of unrelated utterances was a <a href=/posts/kbhhypothesis_testing/#significance-level>statistically significant</a> metric to figure differences between the three experimental groups.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbalagopalan_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbalagopalan_2021/>Balagopalan 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.635945</p><h2 id=one-liner>One-Liner</h2><p>extracted lexicographic and syntactical features from <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> data and trained it on various models, with BERT performing the best.</p><h2 id=novelty>Novelty</h2><p>???????</p><p>Seems like results here are a strict subset of <a href=/posts/kbhzhu_2021/>Zhu 2021</a>. Same sets of dataprep of <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a> but trained on a BERT now. Seem to do worse than <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a> too.</p><h2 id=notable-methods>Notable Methods</h2><p>Essentially <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a></p><ul><li>Also performed <a href=/posts/kbhmmse/>MMSE</a> score regression.</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=table-7-training-result>Table 7 training result</h3><figure><img src=/ox-hugo/2022-06-25_11-47-38_screenshot.png></figure><p>This figure shows us that the results attained by training on extracted feature is past the state-of-the-art at the time.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhchlasta_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhchlasta_2021/>Chlasta 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fpsyg.2020.623237</p><h2 id=one-liner--thrice>One-Liner (thrice)</h2><ol><li>Used features extracted by <a href=/posts/kbhvggish/>VGGish</a> from raw acoustic audio against a SVM, Perceptron, 1NN; got \(59.1\%\) classif. accuracy for dementia</li><li>Then, trained a CNN on raw wave-forms and got \(63.6\%\) accuracy</li><li>Then, they fine-tuned a <a href=/posts/kbhvggish/>VGGish</a> on the raw wave-forms and didn&rsquo;t report their results and just said &ldquo;we discovered that audio transfer learning with a pretrained VGGish feature extractor performs better&rdquo; Gah!</li></ol><h2 id=novelty>Novelty</h2><p>Threw the kitchen sink to process only raw acoustic input, most of it missed; wanted 0 human involvement. It seems like last method is promising.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhguo_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhguo_2021/>Guo 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.642517</p><h2 id=one-liner>One-Liner</h2><p>Used WLS data to augment <a href=/posts/kbhctp/>CTP</a> from <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> and trained it on a BERT with good results.</p><h2 id=novelty>Novelty</h2><ul><li>Used WLS data with <a href=/posts/kbhctp/>CTP</a> task to augment ADReSS <a href=/posts/kbhdementiabank/>DementiaBank</a> data</li></ul><h2 id=notable-methods>Notable Methods</h2><p>WLS data is not labeled, so authors used <a href=/posts/kbhsemantic_verbal_fluency/>Semantic Verbal Fluency</a> tests that come with WLS to make a presumed conservative diagnoses. Therefore, control data is more interesting:</p><h2 id=key-figs>Key Figs</h2><h3 id=table-2>Table 2</h3><figure><img src=/ox-hugo/2022-06-25_11-27-14_screenshot.png></figure><p>Data-aug of <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> data with WSL controls (no presumed AD) trained with a BERT. As expected the conservative control data results in better ferf</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhjonell_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhjonell_2021/>Jonell 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.642633</p><h2 id=one-liner>One-Liner</h2><p>Developed a kitchen sink of diagnoses tools and correlated it with biomarkers.</p><h2 id=novelty>Novelty</h2><p>The kitchen sink of data collection (phones, tablet, eye tracker, microphone, wristband) and the kitchen sink of noninvasive data imaging, psych, speech assesment, clinical metadata.</p><h2 id=notable-methods>Notable Methods</h2><p>Here&rsquo;s their kitchen sink</p><figure><img src=/ox-hugo/2022-06-24_21-06-49_screenshot.png></figure><p>I have <strong><strong>no idea</strong></strong> why a thermal camera is needed</p><h2 id=key-figs>Key Figs</h2><p>Here are the features they extracted</p><figure><img src=/ox-hugo/2022-06-24_21-07-27_screenshot.png></figure><p>Developed the features collected via a method similar to action research, did two passes and refined/added information after preliminary analysis. Figure above also include info about whether or not the measurement was task specific.</p></span></div><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>⟸</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>⟵</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/tags/ntj/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/tags/ntj/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>