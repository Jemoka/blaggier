<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Ntj</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Ntj</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlaguarta_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhlaguarta_2021/>Laguarta 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.624694</p><h2 id=one-liner>One-Liner</h2><p>Proposed a large multimodal approach to embed auditory info + biomarkers for baseline classification.</p><h2 id=novelty>Novelty</h2><p>Developed a massively multimodal audio-to-embedding correlation system that maps audio to biomarker information collected (mood, memory, respiratory) and demonstrated its ability to discriminate cough results for COVID. (they were looking for AD; whoopsies)</p><h2 id=notable-methods>Notable Methods</h2><ul><li>Developed a feature extraction model for AD detection named <a href=/posts/kbhopen_voice_brain_model/>Open Voice Brain Model</a></li><li>Collected a dataset on people coughing and correlated it with biomarkers</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=figure-2>Figure 2</h3><p>This is <strong><strong>MULTI-MODAL</strong></strong> as heck</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlindsay_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhlindsay_2021/>Lindsay 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.642033</p><h2 id=one-liner>One-Liner</h2><p>Proposed cross-linguistic markers shared for AD patients between English and French; evaluated features found with standard ML.</p><h2 id=novelty>Novelty</h2><p>Multi-lingual, cross-linguistic analysis.</p><h2 id=notable-methods>Notable Methods</h2><ul><li>Looked at common patters between the two languages</li><li>Linguistic results scored by <a href=/posts/kbhiu/>IU</a>s on <a href=/posts/kbhctp/>CTP</a> task</li><li></li></ul><h2 id=key-figs>Key Figs</h2><h3 id=figure-1>Figure 1</h3><figure><img src=/ox-hugo/2022-06-24_23-26-39_screenshot.png></figure><p>This figure tells us the various approaches measured.</p><h3 id=table-2>Table 2</h3><figure><img src=/ox-hugo/2022-06-24_23-31-43_screenshot.png></figure><p>Here&rsquo;s a list of semantic features extracted</p><h3 id=table-3>Table 3</h3><figure><img src=/ox-hugo/2022-06-24_23-32-18_screenshot.png></figure><p>Here&rsquo;s a list of NLP features extracted. Bolded items represent P &lt;0.001 correlation for AD/NonAD difference between English and French.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhluz_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhluz_2021/>Luz 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.1101/2021.03.24.21254263</p><h2 id=one-liner>One-Liner</h2><p>Review paper presenting the \(ADReSS_o\) challenge and current baselines for three tasks</p><h2 id=notes>Notes</h2><p>Three tasks + state of the art:</p><ul><li>Classification of AD: accuracy \(78.87\%\)</li><li>Prediction of <a href=/posts/kbhmmse/>MMSE</a> score: RMSE \(5.28\)</li><li>Prediction of cognitive decline: accuracy \(68.75\%\)</li></ul><h3 id=task-1>Task 1</h3><p>AD classification baseline established by decision tree with <a href=/posts/kbhfusion/#late-fusion>late fusion</a></p><figure><img src=/ox-hugo/2022-06-25_22-57-05_screenshot.png></figure><p>(<a href=/posts/kbhloo/>LOOCV</a> and test)</p><h3 id=task-2>Task 2</h3><p><a href=/posts/kbhmmse/>MMSE</a> score prediction baseline established by <a href=/posts/kbhgrid_search/>grid search</a> on parameters.</p><figure><img src=/ox-hugo/2022-06-25_22-58-42_screenshot.png></figure><p>SVR did best on both counts; results from either model are averaged for prediction.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmahajan_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmahajan_2021/>Mahajan 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.623607</p><h2 id=one-liner>One-Liner</h2><p>Trained a bimodal model on speech/text with GRU on speech and CNN-LSTM on text.</p><h2 id=novelty>Novelty</h2><ul><li>A post-2019 NLP paper that doesn&rsquo;t use transformers! (so <del>faster</del> (they used CNN-LSTM) lighter easier)</li><li>&ldquo;Our work sheds light on why the accuracy of these models drops to 72.92% on the ADReSS dataset, whereas, they gave state of the art results on the DementiaBank dataset.&rdquo;</li></ul><h2 id=notable-methods>Notable Methods</h2><p>Bi-Modal audio and transcript processing vis a vi <a href=/posts/kbhshah_2021/>Shah 2021</a>, but with a CNN-LSTM and GRU on the other side.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmartinc_2021/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmartinc_2021/>Martinc 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.642647</p><h2 id=one-liner>One-Liner</h2><p>Combined bag-of-words on transcript + <a href=/posts/kbhactive_data_representation/>ADR</a> on audio to various classifiers for AD; ablated BERT&rsquo;s decesion space for attention to make more easy models in the future.</p><h2 id=novelty>Novelty</h2><ul><li>Pre-processed each of the two modalities before fusing it (<a href=/posts/kbhfusion/#late-fusion>late fusion</a>)</li><li>Archieved \(93.75\%\) accuracy on AD detection</li><li>The data being forced-aligned and fed with <a href=/posts/kbhfusion/#late-fusion>late fusion</a> allows one to see what sounds/words the BERT model was focusing on by just focusing on the attention on the words</li></ul><h2 id=notable-methods>Notable Methods</h2><ul><li>Used classic cookie theft data</li><li>bag of words to do <a href=/posts/kbhactive_data_representation/>ADR</a> but for words</li><li>multimodality but <a href=/posts/kbhfusion/#late-fusion>late fusion</a> with one (hot-swappable) classifier</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=how-they-did-it>How they did it</h3><figure><img src=/ox-hugo/2022-06-24_00-20-26_screenshot.png></figure><p>This is how the combined the forced aligned (:tada:) audio and transcript together.</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/tags/ntj/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>