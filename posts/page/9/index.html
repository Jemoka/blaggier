<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhacl2025_orals_efficient_nlp/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhacl2025_orals_efficient_nlp/>ACL2025 Orals: Efficient NLP</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhacl2025_orals_language_modeling_1/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhacl2025_orals_language_modeling_1/>ACL2025 Orals: Language Modeling 1</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><ul><li><a href=/posts/kbhacl2025_li/>ACL2025 Li: TokAlign Token Alignment</a></li><li><a href=/posts/kbhacl2025_pagoni/>ACL2025 Pagoni: Patches Scale Better Than Tokens</a></li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhacl2025_orals/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhacl2025_orals/>ACL2025 Orals: QA</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><ul><li><a href=/posts/kbhacl2025_huang_making_in_multi_hop_qa/>ACL2025 Huang: Making in Multi-Hop QA</a></li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhacl2025_pagoni/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhacl2025_pagoni/>ACL2025 Pagoni: Patches Scale Better Than Tokens</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=one-liner>One-Liner</h2><p>&ldquo;Patches in groups of tokenization scale better than tokens&rdquo;</p><h2 id=motivation-novelty>Motivation / Novelty</h2><ul><li>typical byte-level LMs don&rsquo;t are very expensive because many tokens</li><li>its hard to go beyond 4-6 bytes per token: <a href=/posts/kbhzipf_s_law/>Zipf&rsquo;s Law</a></li><li>so, we model them as <a href=#token-patch>token patch</a>es</li></ul><h2 id=notable-methods>Notable Methods</h2><h3 id=token-patch>token patch</h3><p>&ldquo;how do we segment the byte sequence into patches?&rdquo; &mdash; insight: group predicable tokens after every hard choice! i.e., once you train a model, there are &ldquo;obvious&rdquo;</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhacl_tuesday_afternoon_posters/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhacl_tuesday_afternoon_posters/>ACL2025 Tuesday Afternoon Posters</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=acl2025-wu-rankcot-refining-knowledge-for-retrieval-augmented-generation-through-ranking-cot>ACL2025 Wu: RankCoT refining knowledge for retrieval augmented generation through ranking CoT</h2><p>Key insight: generally a bunch of chain of thoughts, including on irrelevant documents, re-rank using self reflection, and then DPO</p><h2 id=acl2025-trienes-behavioral-analysis-of-information-salience>ACL2025 Trienes: behavioral analysis of information salience</h2><p>Key insight: you can ask models for summaries at shorter lengths, which distill what the models think is salient information</p><h2 id=acl2025-abbes-small-encoders-can-rival-large-encoders-in-detecting-groundedness>ACL2025 Abbes: small encoders can rival large encoders in detecting groundedness</h2><p>Key insight: apparently groundedness classification doesn&rsquo;t require that many parameters</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/8/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/7/ aria-label="Page 7" class=page-link role=button>7</a></li><li class=page-item><a href=/posts/page/8/ aria-label="Page 8" class=page-link role=button>8</a></li><li class="page-item active"><a aria-current=page aria-label="Page 9" class=page-link role=button>9</a></li><li class=page-item><a href=/posts/page/10/ aria-label="Page 10" class=page-link role=button>10</a></li><li class=page-item><a href=/posts/page/11/ aria-label="Page 11" class=page-link role=button>11</a></li><li class=page-item><a href=/posts/page/10/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>