<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmaximal_interval/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmaximal_interval/>maximal interval</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>a <a href=/posts/kbhmaximal_interval/>maximal interval</a> is the largest interval you can fit while the function is finite while the function is finite.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmaximum_a_posteriori_estimate/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmaximum_a_posteriori_estimate/>maximum a posteriori estimate</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhmaximum_a_posteriori_estimate/>maximum a posteriori estimate</a> is a <a href=/posts/kbhparameter_learning/>parameter learning</a> scheme that uses <a href=/posts/kbhbaysian_parameter_learning/#beta-distribution>Beta Distribution</a> and <a href=/posts/kbhbaysian_network/>Baysian inference</a> to get a distribution of the posterior of the parameter, and return the <a href=/posts/kbhargmax/>argmax</a> (i.e. the mode) of the <a href=/posts/kbhmaximum_a_posteriori_estimate/>MAP</a>.</p><p>This differs from <a href=/posts/kbhmaximum_likelihood_parameter_learning/>MLE</a> because we are considering a <em>distribution</em> of possible parameters:</p><p>\begin{equation}
p\qty (\theta \mid x_1, \dots, x_{n})
\end{equation}</p><hr><p>Calculating a <a href=/posts/kbhmaximum_a_posteriori_estimate/>MAP</a> posterior, in general:</p><p>\begin{equation}
\theta_{MAP} = \arg\max_{\theta} P(\theta|x_1, \dots, x_{n}) = \arg\max_{\theta} \frac{f(x_1, \dots, x_{n} | \theta) g(\theta)}{h(x_1, \dots, x_{n})}
\end{equation}</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmaximum_likelihood_parameter_learning/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmaximum_likelihood_parameter_learning/>Maximum Likelihood Parameter Learning</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>&ldquo;We find the <a href=/posts/kbhparameter/>parameter</a> that maximizes the likelihood.&rdquo;</p><ol><li>for each \(X_{j}\), sum<ol><li>what&rsquo;s the <a href=#log-likelihood>log-likelihood</a> of one \(X_{i}\)</li></ol></li><li>take derivative w.r.t. \(\theta\) and set to \(0\)</li><li>solve for \(\theta\)</li></ol><p>(this maximizes the <a href=#log-likelihood>log-likelihood</a> of the data!)</p><p>that is:</p><p>\begin{equation}
\theta_{MLE} = \arg\max_{\theta} P(x_1, \dots, x_{n}|\theta) = \arg\max_{\theta} \qty(\sum_{i=1}^{n} \log(f(x_{i}|\theta)) )
\end{equation}</p><hr><p>If your \(\theta\) is a vector of more than \(1\) thing, take the gradient (i.e. partial derivative against each of your variables) of the thing and solve the place where the gradient is identically \(0\) (each slot is \(0\)). That is, we want:</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmaxq/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmaxq/>MaxQ</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=two-abstractions>Two Abstractions</h2><ul><li>&ldquo;temporal abstractions&rdquo;: making decisions without consideration / abstracting away time (<a href=/posts/kbhmarkov_decision_process/>MDP</a>)</li><li>&ldquo;state abstractions&rdquo;: making decisions about groups of states at once</li></ul><h2 id=graph>Graph</h2><p><a href=/posts/kbhmaxq/>MaxQ</a> formulates a policy as a graph, which formulates a set of \(n\) policies</p><figure><img src=/ox-hugo/2024-02-13_09-50-20_screenshot.png></figure><h3 id=max-node>Max Node</h3><p>This is a &ldquo;policy node&rdquo;, connected to a series of \(Q\) nodes from which it takes the max and propegate down. If we are at a leaf max-node, the actual action is taken and control is passed back t to the top of the graph</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmbp/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmbp/>MBP</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/170/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/169/ aria-label="Page 169" class=page-link role=button>169</a></li><li class=page-item><a href=/posts/page/170/ aria-label="Page 170" class=page-link role=button>170</a></li><li class="page-item active"><a aria-current=page aria-label="Page 171" class=page-link role=button>171</a></li><li class=page-item><a href=/posts/page/172/ aria-label="Page 172" class=page-link role=button>172</a></li><li class=page-item><a href=/posts/page/173/ aria-label="Page 173" class=page-link role=button>173</a></li><li class=page-item><a href=/posts/page/172/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>