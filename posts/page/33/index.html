<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_1_b/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_1_b/>Axler 1.B</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>\(\mathbb{F}^{n}\) not being a <a href=/posts/kbhfield/>field</a> kinda sucks, so we made an object called a &ldquo;<a href=/posts/kbhvector_space/>vector space</a>&rdquo; which essentially does everything a <a href=/posts/kbhfield/>field</a> does except without necessitating a <a href=/posts/kbhinverses/>multiplicative inverse</a></li><li>Formally, a <a href=/posts/kbhvector_space/>vector space</a> is <a href=/posts/kbhclosed/>closed</a> over <a href=/posts/kbhadding/>addition</a> and have a <a href=/posts/kbhscalar_multiplication/>scalar multiplication</a>. Its <a href=/posts/kbhadding/>addition</a> is <a href=/posts/kbhcommutivity/>commutative</a>, both <a href=/posts/kbhadding/>addition</a> and <a href=/posts/kbhscalar_multiplication/>scalar multiplication</a> is <a href=/posts/kbhassociative/>associative</a>, and <a href=/posts/kbhdistributivity/>distributivity</a> holds. There is an <a href=/posts/kbhadditive_identity/>additive identity</a>, <a href=/posts/kbhinverses/>additive inverse</a>, and <a href=/posts/kbhmultiplicative_identity/>multiplicative identity</a>.</li><li>We defined something called \(\mathbb{F}^{S}\), which is the set of functions from a set \(S\) to \(\mathbb{F}\). Turns out, <a href=/posts/kbhfs_is_a_vector_space/>\(\mathbb{F}^{S}\) is a Vector Space Over \(\mathbb{F}\)</a> and we can secretly treat \(\mathbb{F}^{n}\) and \(\mathbb{F}^{\infty}\) as special cases of \(\mathbb{F}^{s}\).</li><li>We established that <a href=/posts/kbhidentity/>identity</a> and <a href=/posts/kbhinverses/>inverse</a> are unique additively in <a href=/posts/kbhvector_space/>vector space</a>s.</li><li>Lastly, we proved some expressions we already know: \(0v=0\), \(-1v=-v\).</li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhadding/>addition</a> and <a href=/posts/kbhscalar_multiplication/>scalar multiplication</a></li><li><a href=/posts/kbhvector_space/>vector space</a> and <a href=/posts/kbhvector/>vector</a>s</li><li><a href=/posts/kbhvector_space/#vector-space-over-fields>vector space &ldquo;over&rdquo; fields</a></li><li>\(V\) denotes a vector space over \(\mathbb{F}\)</li><li>\(-v\) is defined as the <a href=/posts/kbhinverses/>additive inverse</a> of \(v \in V\)</li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhfinfty_is_a_vector_space_over_f/>\(\mathbb{F}^{\infty}\) is a Vector Space over \(\mathbb{F}\)</a></li><li><a href=/posts/kbhfs_is_a_vector_space/>\(\mathbb{F}^{S}\) is a Vector Space Over \(\mathbb{F}\)</a></li><li>All <a href=/posts/kbhvector_space/>vector space</a>s \(\mathbb{F}^{n}\) and \(\mathbb{F}^{\infty}\) are just special cases \(\mathbb{F}^{S}\): you can think about those as a mapping from coordinates \((1,2,3, \dots )\) to their actual values in the &ldquo;vector&rdquo;</li><li><a href=/posts/kbhadditive_identity_is_unique_in_a_vector_space/>additive identity is unique in a vector space</a></li><li><a href=/posts/kbhadditive_inverse_is_unique_in_a_vector_space/>additive inverse is unique in a vector space</a></li><li><a href=/posts/kbhzero_times_vector/>\(0v=0\)</a>, both ways (for zero scalars and vectors)</li><li><a href=/posts/kbh1v_1/>\(-1v=-v\)</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>The way Axler presented the idea of &ldquo;over&rdquo; is a tad weird; is it really only scalar multiplication which hinders vector spaces without \(\mathbb{F}\)? In other words, do the sets that form vector spaces, apart from the \(\lambda\) used for scalar multiplication, need anything to do with the \(\mathbb{F}\) they are &ldquo;over&rdquo;?</del> The <strong>name</strong> of the field and what its <strong>over</strong> do not have to be the same&mdash;&ldquo;vector space \(\mathbb{C}^2\) over \(\{0,1\}\)&rdquo; is a perfectly valid statement</li><li><del>If lists have finite length \(n\), then what are the elements of \(\mathbb{F}^{\infty}\) called?</del> &ldquo;we could think about \(\mathbb{F}^{\infty}\), but we aren&rsquo;t gonna.&rdquo;</li><li><del>Why is \(1v=v\) an axiom, whereas we say that <em>some</em> \(0\) exists?</del> because we know 1 already, and you can follow the behavor of scalar multiplication</li><li><del>what&rsquo;s that thing called again in proofs where you just steal the property of a constituent element?</del>: inherits</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><ul><li>The simplest vector space is \(\{0\}\)</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_1_c/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_1_c/>Axler 1.C</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined <a href=/posts/kbhsubspace/>subspace</a> and how to check for them</li><li>we want to operate on subsets, so we defined the <a href=/posts/kbhsum_of_subsets/>sum of subsets</a></li><li>we saw that the <a href=/posts/kbhsum_of_subsets/>sum of subspaces</a> are the <a href=/posts/kbhsum_of_subsets/#sum-of-subspaces-is-the-smallest-subspace-with-both-subspaces>smallest containing subspace</a></li><li>and finally, we defined <a href=/posts/kbhdirect_sum/>direct sum</a>s and how to prove them</li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhsubspace/>subspace</a></li><li><a href=/posts/kbhsum_of_subsets/>sum of subsets</a></li><li><a href=/posts/kbhdirect_sum/>direct sum</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li>checking for subspaces<ul><li><a href=/posts/kbhsubspace/#simplified-check-for-subspace>simplified check for subspace</a></li><li><a href=/posts/kbhsum_of_subsets/#sum-of-subspaces-is-the-smallest-subspace-with-both-subspaces>sum of subspaces is the smallest subspace with both subspaces</a></li></ul></li><li>creating direct sums<ul><li><a href=/posts/kbhdirect_sum/#a-id-1b800658-2f83-4802-acfd-2d15cf5a1d74-sum-of-subsets-is-a-id-4e586014-c91f-4d52-98bb-a2fe11a75007-direct-sum-id-fddf0648-91ea-4c5b-8298-fa0a30637cb7-iff-there-is-only-one-way-to-write-0>a sum of subsets is a direct sum IFF there is only one way to write \(0\)</a></li><li><a href=/posts/kbhdirect_sum/#a-id-1b800658-2f83-4802-acfd-2d15cf5a1d74-sum-of-subsets-is-only-a-id-4e586014-c91f-4d52-98bb-a2fe11a75007-direct-sum-id-fddf0648-91ea-4c5b-8298-fa0a30637cb7-iff-their-intersection-is-set-containing-0>a sum of subsets is only a direct sum IFF their intersection is the set containing \(0\)</a></li></ul></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>Does the <a href=/posts/kbhadditive_identity/>additive identity</a> have be the same between different <a href=/posts/kbhsubspace/>subspace</a>s of the same <a href=/posts/kbhvector_space/>vector space</a>?</del> yes, otherwise the larger <a href=/posts/kbhvector_space/>vector space</a> has two <a href=/posts/kbhadditive_identity/>additive identities</a>.</li><li><del>Does the <a href=/posts/kbhadding/>addition</a> and <a href=/posts/kbhmultiplying/>multiplication</a> operations in a <a href=/posts/kbhsubspace/>subspace</a> have to be the same as its constituent <a href=/posts/kbhvector_space/>vector space</a>?</del> by definition</li><li><del>Why are <a href=/posts/kbhdirect_sum/>direct sum</a>s defined on sub-<strong><strong>spaces</strong></strong> and not <a href=/posts/kbhsum_of_subsets/>sum of subsets</a>?</del> because the union is usually not a <a href=/posts/kbhsubspace/>subspace</a> so we use sums and keep it in subspaces</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_1_c_excercises/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_1_c_excercises/>Axler 1.C Exercises</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>3: Show that the set of differential real-valued functions \(f\) on the interval \((-4,4)\) such that \(f&rsquo;(-1)=3f(2)\) is a subspace of \(\mathbb{R}^{(-4,4)}\)</p><hr><p>4: Suppose \(b \in R\). Show that the set of continuous real-valued functions \(f\) on the interval \([0,1]\) such that \(\int_{0}^{1}f=b\) is a subspace of \(\mathbb{R}^{[0,1]}\) IFF \(b=0\)</p><p>Additive Identity:</p><p>assume \(\int_{0}^{1}f=b\) is a subspace</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_2_a/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_2_a/>Axler 2.A</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined the combination of a list of vectors as a <a href=/posts/kbhlinear_combination/>linear combination</a> and defined set of all <a href=/posts/kbhlinear_combination/>linear combination</a> of <a href=/posts/kbhvector/>vector</a>s to be called a <a href=/posts/kbhspan/>span</a></li><li>we defined the idea of a <a href=/posts/kbhfinite_dimensional_vector_space/>finite-dimensional vector space</a> vis a vi <a href=/posts/kbhspan/#spans>spanning</a></li><li>we took a god-forsaken divergence into <a href=/posts/kbhpolynomial/>polynomial</a>s that will surely not come back and bite us in chapter 4</li><li>we defined <a href=/posts/kbhlinear_independence/>linear independence</a> + <a href=/posts/kbhlinear_independence/#linearly-dependent>linear dependence</a> and, from those definition, proved the actual usecase of these concepts which is the <a href=/posts/kbhlinear_dependence_lemma/>Linear Dependence Lemma</a></li><li>we apply the <a href=/posts/kbhlinear_dependence_lemma/>Linear Dependence Lemma</a> to show that <a href=/posts/kbhlinear_independence/#length-of-linearly-independent-list-leq-length-of-spanning-list>length of linearly-independent list \(\leq\) length of spanning list</a> as well as that <a href=/posts/kbhsubspace/#finite-dimensional-subspaces>finite-dimensional vector spaces make finite subspaces</a>. Both of these proofs work by making <a href=/posts/kbhlinear_independence/>linearly independent</a> lists&mdash;the former by taking a <a href=/posts/kbhspan/#spans>spanning</a> list and making it smaller and smaller, and the latter by taking a <a href=/posts/kbhlinear_independence/>linearly independent</a> list and making it bigger and bigger</li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhlinear_combination/>linear combination</a></li><li><a href=/posts/kbhspan/>span</a> + &ldquo;<a href=/posts/kbhspan/#spans>spans</a>&rdquo;</li><li><a href=/posts/kbhfinite_dimensional_vector_space/>finite-dimensional vector space</a><ul><li><a href=/posts/kbhfinite_dimensional_vector_space/>infinite-demensional vector space</a></li><li><a href=/posts/kbhsubspace/#finite-dimensional-subspaces>finite-dimensional subspaces</a></li></ul></li><li><a href=/posts/kbhpolynomial/>polynomial</a><ul><li><a href=/posts/kbhpolynomial/#mathcal-p--mathbb-f>\(\mathcal{P}(\mathbb{F})\)</a></li><li><a href=/posts/kbhpolynomial/#mathcal-p-m--mathbb-f>\(\mathcal{P}_{m}(\mathbb{F})\)</a></li><li><a href=/posts/kbhpolynomial/#degree-of-a-polynomial-deg-p>degree of a polynomial \(\deg p\)</a></li></ul></li><li><a href=/posts/kbhlinear_independence/>linear independence</a> and <a href=/posts/kbhlinear_independence/#linearly-dependent>linear dependence</a></li><li><a href=/posts/kbhlinear_dependence_lemma/>Linear Dependence Lemma</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhspan/#span-is-the-smallest-subspace-containing-all-vectors-in-the-list>span is the smallest subspace containing all vectors in the list</a></li><li><a href=/posts/kbhpolynomial/#mathcal-p--mathbb-f--is-a-vector-space-over-mathbb-f>\(\mathcal{P}(\mathbb{F})\) is a vector space over \(\mathbb{F}\)</a></li><li>the world famous <a href=/posts/kbhlinear_dependence_lemma/>Linear Dependence Lemma</a> and its fun <a href=/posts/kbhlinear_dependence_lemma/#issue>issue</a></li><li><a href=/posts/kbhlinear_independence/#length-of-linearly-independent-list-leq-length-of-spanning-list>length of linearly-independent list \(\leq\) length of spanning list</a></li><li><a href=/posts/kbhsubspace/#finite-dimensional-subspaces>subspaces of inite-dimensional vector spaces is finite dimensional</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>obviously <a href=/posts/kbhpolynomial/>polynomial</a>s are non-linear structures; under what conditions make them nice to work with in linear algebra?</del></li><li><del>what is the &ldquo;obvious way&rdquo; to change <a href=/posts/kbhlinear_dependence_lemma/>Linear Dependence Lemma</a>&rsquo;s part \(b\) to make \(v_1=0\) work?</del></li><li>for the <a href=/posts/kbhsubspace/#finite-dimensional-subspaces>finite-dimensional subspaces</a> proof, though we know that the process terminates, how do we know that it terminates at a <a href=/posts/kbhspan/#spans>spanning</a> list of \(U\) and not just a <a href=/posts/kbhlinear_independence/>linearly independent</a> list in \(U\)?</li><li>direct sum and linear independence related; how exactly?</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><p>I just ate an entire Chinese new-year worth of food while typing this up. That&rsquo;s worth <em>something</em> right</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_2_b/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_2_b/>Axler 2.B</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined <a href=/posts/kbhbasis/>basis</a> of a <a href=/posts/kbhvector_space/>vector space</a>&mdash;a <a href=/posts/kbhlinear_independence/>linearly independent</a> <a href=/posts/kbhspan/#spans>spanning</a> list of that <a href=/posts/kbhvector_space/>vector space</a>&mdash;and shown that to <a href=/posts/kbhbasis/#criteria-for-id-f88170b1-08b5-48a7-a7b5-1ace768e7b28-basis>be a basis</a> one has to be able to write a write an unique <a href=/posts/kbhspan/#spans>spanning</a> list</li><li>we show that you can <a href=/posts/kbhbasis/#all-id-e8109222-5548-4d08-b6df-8f933f2dbb36-spanning-lists-contains-a-id-f88170b1-08b5-48a7-a7b5-1ace768e7b28-basis-of-which-you-are-id-e8109222-5548-4d08-b6df-8f933f2dbb36-spanning>chop a spanning list of a space down to a basis</a> or <a href=/posts/kbhbasis/#a-id-45384b28-f1e3-4fb1-aeb2-21c875834744-linearly-independent-list-expends-to-a-id-f88170b1-08b5-48a7-a7b5-1ace768e7b28-basis>build a linearly independent list up to a basis</a></li><li>because of this, you can make a <a href=/posts/kbhspan/#spans>spanning</a> list of <a href=/posts/kbhfinite_dimensional_vector_space/>finite-dimensional vector spaces</a> and <a href=/posts/kbhfinite_dimensional_vector_space/#every-id-4ed27ed5-4edc-4ef4-afd7-9b8e3bcd9b96-finite-dimensional-vector-space-has-a-id-f88170b1-08b5-48a7-a7b5-1ace768e7b28-basis>chop it down to a basis</a>: so every <a href=/posts/kbhfinite_dimensional_vector_space/>finite-dimensional vector space</a> has a <a href=/posts/kbhbasis/>basis</a></li><li>lastly, we can use the fact that you can grow <a href=/posts/kbhlist/>list</a> to <a href=/posts/kbhbasis/>basis</a> to show that <a href=/posts/kbhdirect_sum/#every-id-345c37fa-5d4c-44e9-ad03-2fe7e5a37224-subspace-of-v-is-a-part-of-a-id-4e586014-c91f-4d52-98bb-a2fe11a75007-direct-sum-equaling-to-v>every subspace of \(V\) is a part of a direct sum equaling to \(V\)</a></li></ul><h2 id=new-definitions>New Definitions</h2><p><a href=/posts/kbhbasis/>basis</a> and <a href=/posts/kbhbasis/#criteria-for-id-f88170b1-08b5-48a7-a7b5-1ace768e7b28-basis>criteria for basis</a></p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/32/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/31/ aria-label="Page 31" class=page-link role=button>31</a></li><li class=page-item><a href=/posts/page/32/ aria-label="Page 32" class=page-link role=button>32</a></li><li class="page-item active"><a aria-current=page aria-label="Page 33" class=page-link role=button>33</a></li><li class=page-item><a href=/posts/page/34/ aria-label="Page 34" class=page-link role=button>34</a></li><li class=page-item><a href=/posts/page/35/ aria-label="Page 35" class=page-link role=button>35</a></li><li class=page-item><a href=/posts/page/34/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>