<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhiclr2025_li_moe_is_secretly_an_embedding/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhiclr2025_li_moe_is_secretly_an_embedding/>ICLR2025 Li: MoE is secretly an embedding</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=motivation>motivation</h2><p>Can we directly extract embeddings from MoE forwarding routing weights (i.e., compared to traditional residual stream information)?</p><h2 id=key-insight>Key Insight</h2><p>Using residual states vs. forwarding weights as semantic searc embeddings offer complementary strengths (i.e., when one method fails, the other one succeeds more)</p><h2 id=method>Method</h2><p>Create an aggregate embedding:</p><p>\begin{equation}
E_{j} = X_{j} + \alpha W_{j}
\end{equation}</p><p>where \(W_{j}\) is the routing weight of the residual, and \(X_{j}\) is the residual.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhiclr2025_mathur_mind_adaptive_thinking_with_dynamic_computation/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhiclr2025_mathur_mind_adaptive_thinking_with_dynamic_computation/>ICLR2025 Mathur: MIND Adaptive Thinking with Dynamic Computation</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=motivation>Motivation</h2><p>Standard computation doesn&rsquo;t adapt.</p><h2 id=fixed-point-iteration-for-adaptation>Fixed-Point Iteration for Adaptation</h2><h3 id=method-cnn>method: CNN</h3><ol><li>for every layer, perform <a href=/posts/kbhfixed_point_iteration/>fixed-point iteration</a> until convergence to mask out (what exactly?)</li><li>supervise also an &ldquo;introspection model&rdquo; to skip the entire fixed point</li><li>loss: LM + supervision for the introspection model</li></ol><h3 id=method-mind-transformer>method: MIND-transformer</h3><ol><li>for every layer, perform <a href=/posts/kbhfixed_point_iteration/>fixed-point iteration</a> until attention activation convergence</li><li>ditto introspection as above</li></ol></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhiclr2025_moe/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhiclr2025_moe/>ICLR2025 MoE</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=talks>Talks</h2><ul><li><a href=/posts/kbhiclr2025_li_moe_is_secretly_an_embedding/>ICLR2025 Li: MoE is secretly an embedding</a></li><li><a href=/posts/kbhiclr2025_jin_moe_zero_computation_experts/>ICLR2025 Jin: MOE++ zero computation experts</a></li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhiclr2025_neitemeier_hierachical_autoregressive_transformers/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhiclr2025_neitemeier_hierachical_autoregressive_transformers/>ICLR2025 Neitemeier: Hierachical Autoregressive Transformers</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>&ldquo;A Byte Level transformer, with some compression&rdquo;</p><p><strong>Key insight</strong>: use a [CLS] token in front of every word to train a small &ldquo;tokenizer&rdquo;, and then do a normal transformer on the [CLS] tokens, and then autoregressive decode out the single bytes.</p><h2 id=method>Method</h2><h3 id=hierarchical-autoregressive-transformers>Hierarchical Autoregressive Transformers</h3><p>We put a [cls] in front of every word. So the input looks like</p><pre tabindex=0><code class=language-nil data-lang=nil>[CLS] M y _ [CLS] n a m e _ [CLS] i s
</code></pre><p>We then run a small encoder over each sequence. And then you take the encoded [CLS], and run</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhiclr2025_saturday_posters/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhiclr2025_saturday_posters/>ICLR2025 Saturday Posters</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=iclr2025-cassidy-assistancezero>ICLR2025 Cassidy: AssistanceZero</h2><ol><li>Train reward predictor to also have rewards at test time</li><li>MCTS</li><li>Learn to match root node KL</li></ol><h2 id=iclr2025-liu-synthesizing-programmatic-reinforcement-learning-policies-with-llm-guided-search>ICLR2025 Liu: synthesizing programmatic reinforcement learning policies with LLM guided search</h2><p>Hill climbing with partial mutations of generated programs of LLMs</p><h2 id=iclr2025-weller-l-prompttrirver>ICLR2025 Weller: l PromptTrirver</h2><p>??</p><h2 id=iclr2025-yu-robust-llm-safeguard-via-refusal-feature-adversarial-training>ICLR2025 Yu: robust LLM safeguard via refusal feature adversarial training</h2><p>With mechanistic interpretability, we can find a sub space which is correlated with refusal, pull that up</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/134/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/133/ aria-label="Page 133" class=page-link role=button>133</a></li><li class=page-item><a href=/posts/page/134/ aria-label="Page 134" class=page-link role=button>134</a></li><li class="page-item active"><a aria-current=page aria-label="Page 135" class=page-link role=button>135</a></li><li class=page-item><a href=/posts/page/136/ aria-label="Page 136" class=page-link role=button>136</a></li><li class=page-item><a href=/posts/page/137/ aria-label="Page 137" class=page-link role=button>137</a></li><li class=page-item><a href=/posts/page/136/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>