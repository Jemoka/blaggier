<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbatchalign_benchmarking/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbatchalign_benchmarking/>Batchalign Benchmarking</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbatchalign_morphosyntax/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbatchalign_morphosyntax/>Batchalign Morphosyntax</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>We now describe the procedure used to perform morpho-syntactic analysis which is used to extract morphological and dependency information, including the morphological features used in this analysis. The core facilities of neural morpho-syntax is provided by the Stanza package ((<a href=#citeproc_bib_item_11>Qi et al. 2020</a>)), on the basis of which we perform myriad customizations in order to support the analysis functionality needed for this work.</p><p>The process of morpho-syntax analysis occurs in five basic steps: 1) performance of raw language sample analysis (LSA) using automatic speech recognition (ASR) and utterance segmentation tools already built into the Batchalign system ((<a href=#citeproc_bib_item_6>Liu et al. 2023</a>)) 2) use of the Stanza tokenizer and multi-word token (MWT) recognizer to obtain initial word-level tokenization of each utterance 3) programmatic, language-specific correction of these tokenization, especially pertaining to multi-word tokens (MWTs) and multi-word forms 4) the invocation of the rest of the Stanza neural pipeline for morphology, dependency, and feature extraction 5) programmatic extraction and correction of output features after the Stanza pipeline.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbatchalign_paper_outline/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbatchalign_paper_outline/>Batchalign Paper Outline</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=things-to-include>Things to include</h2><ul><li>Rev</li><li>How to handle interspersed results</li><li>Utterance segmentation</li><li>Why <code>--prealigned</code> and the overall performance of MFA</li><li>Beginning/End Bullet and why we throw away Rev&rsquo;s output</li><li>fixbullets and manual utterance segmentation</li><li><code>&*INV=</code> interspersed comments</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbayes_normalization_constant/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbayes_normalization_constant/>Bayes Normalization Constant</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>For some <a href=/posts/kbhbaysian_network/>Baysian Network</a> situation, you will note that there&rsquo;s some bodge of values below:</p><p>\begin{equation}
P(A|M) = \frac{P(M|A)P(A)}{P(M)}
\end{equation}</p><p>if we are only interested in a function in terms of different values of \(a\), \(P(M)\) is not that interesting. Therefore, we can just calculate \(A\) for all \(a\), and then normalize it to sum to 1:</p><p>\begin{equation}
P(A|M) \propto P(M|A)P(A)
\end{equation}</p><p>and then, after calculating each \(P(M|A)P(A)\) , we just ensure that each thing sums to one.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbayes_theorem/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhbayes_theorem/>Bayes Theorem</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>\begin{align}
p(x\mid y) = \frac{p(y \mid x) p(x)}{p(y)}
\end{align}</p><p>this is a direct result of the <a href=/posts/kbhprobability/#conditional-probability>probability chain rule</a>.</p><p>Typically, we name \(p(y|x)\) the &ldquo;likelihood&rdquo;, \(p(x)\) the &ldquo;prior&rdquo;.</p><h2 id=better-normalization>Better normalization</h2><p>What if you don&rsquo;t fully know \(p(y)\), say it was parameterized over \(x\)?</p><p>\begin{align}
p(x|y) &= \frac{p(y|x) \cdot p(x)}{p(y)} \\
&= \frac{p(y|x) \cdot p(x)}{\sum_{X_{i}} p(y|X_{i})}
\end{align}</p><p>just apply <a href=/posts/kbhprobability/#law-of-total-probability>law of total probability</a>! taad</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/37/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/36/ aria-label="Page 36" class=page-link role=button>36</a></li><li class=page-item><a href=/posts/page/37/ aria-label="Page 37" class=page-link role=button>37</a></li><li class="page-item active"><a aria-current=page aria-label="Page 38" class=page-link role=button>38</a></li><li class=page-item><a href=/posts/page/39/ aria-label="Page 39" class=page-link role=button>39</a></li><li class=page-item><a href=/posts/page/40/ aria-label="Page 40" class=page-link role=button>40</a></li><li class=page-item><a href=/posts/page/39/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>