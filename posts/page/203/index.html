<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_math530_5_a_problem_35_36/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnus_math530_5_a_problem_35_36/>NUS-MATH530 5.A Problem 35/36</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Warmup: 35</p><p>Suppose \(V\) is finite dimensional, \(T \in \mathcal{L}(V)\) and \(U\) is <a href=/posts/kbhinvariant_subspace/>invariant</a> under \(T\). Prove each eigenvalue of \(T / U\) is an eigenvalue of \(T\).</p><p>Now, \(\lambda\) is an eigenvalue of \(T / U\). That is:</p><p>\begin{equation}
Tv + U = \lambda v + U
\end{equation}</p><p>Meaning:</p><p>\begin{equation}
(T-\lambda I) v \in U, \forall v \in V
\end{equation}</p><p>Suppose for the sake of contradiction \(\lambda\) is not an eigenvalue of \(T\). This means no \(\lambda\) such that \(Tv = \lambda v\); specifically, that means also no \(\lambda\) such that \(T|_{u} u = \lambda u\). Now, that means \(T|_{u} - \lambda I\) is invertible given finite dimensional \(V\).</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_math530_5_c_problem_7/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnus_math530_5_c_problem_7/>NUS-MATH530 5.C Problem 7</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><hr><p>Suppose \(T \in \mathcal{L}(V)\) has a diagonal matrix \(A\) w.r.t. some basis of \(V\), and that \(\lambda \in \mathbb{F}\). Prove that \(\lambda\) appears on the diagonal of \(A\) precisely \(\dim E(\lambda, T)\) times.</p><hr><h2 id=aside-to-appear-on-the-diagonal-n-times>Aside: &ldquo;to appear on the diagonal \(n\) times&rdquo;</h2><p>We want to begin by giving a description for what &ldquo;appearing on the diagonal&rdquo; of a diagonal matrix implies.</p><p>A diagonal matrix is a special-case upper-triangular matrix, so a value being on its diagonal implies it to be an eigenvalue.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_math530_changing_bases/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnus_math530_changing_bases/>NUS-MATH530 Changing Bases</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=standard-bases-back-and-fourth>Standard Bases Back and Fourth</h2><p>To map the vectors from \(B_2\) back to the standard bases, we simply have to construct the map:</p><p>\begin{equation}
\mqty(2 & 1 & 2 \\ 1& 1& -1 \\ 1 & -1 & 0)
\end{equation}</p><p>Each of the &ldquo;standard&rdquo; vectors in the new basis, when applied to this matrix, gets moved back to their original representation.</p><p>Presumably, then, moving &ldquo;forward&rdquo; into the new space is simply taking the inverse of this vector, which we will do separately; its inverse is:</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_math530_geometric_intepretations/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnus_math530_geometric_intepretations/>NUS-MATH530 Geometric Intepretations</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=dot-product>Dot product</h2><h3 id=calculations>Calculations</h3><p>Let&rsquo;s calculate some dot products!</p><p>\begin{equation}
\begin{pmatrix}
1 \\ 0
\end{pmatrix} \cdot \begin{pmatrix}
0 \\ 1
\end{pmatrix} = 0
\end{equation}</p><p>\begin{equation}
\begin{pmatrix}
1 \\2
\end{pmatrix} \cdot \begin{pmatrix}
2 \\1
\end{pmatrix} = 4
\end{equation}</p><p>\begin{equation}
\begin{pmatrix}
1 \\ 1
\end{pmatrix} \cdot \begin{pmatrix}
-1 \\1
\end{pmatrix} = 0
\end{equation}</p><p>\begin{equation}
\begin{pmatrix}
1 \\1
\end{pmatrix} \cdot \begin{pmatrix}
2 \\ 2
\end{pmatrix} = 4
\end{equation}</p><h3 id=interpretation>Interpretation</h3><p>Geometrically, the intepretation of the dot product is the magnitude that comes from scaling the bottom projected value by the top value. This is essentially multiplying the proportion of one vector that&rsquo;s parallel to the other by each other.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_math530_geometric_multiplicity/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnus_math530_geometric_multiplicity/>NUS-MATH530 Geometric Multiplicity</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Let \(\lambda_{m}\) be an eigenvalue for \(T\) an operator on complex finite-dimensional \(V\). Let \(m\) be the geometric multiplicity of \(\lambda_{m}\). We desire that the algebraic multiplicity is at least \(m\). Let \(\dim v = n\).</p><p>We have that \(m\) is the geometric multiplicity of \(\lambda_{m}\), meaning:</p><p>\begin{equation}
\dim E(\lambda_{m}, T) = m
\end{equation}</p><p>This means we can take \(m\) linearly independent eigenvectors from \(V\). Extend this list now to a basis of \(V\) with \(v_1, &mldr;v_{m}, u_{1}, u_{n-m}\).</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/202/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/201/ aria-label="Page 201" class=page-link role=button>201</a></li><li class=page-item><a href=/posts/page/202/ aria-label="Page 202" class=page-link role=button>202</a></li><li class="page-item active"><a aria-current=page aria-label="Page 203" class=page-link role=button>203</a></li><li class=page-item><a href=/posts/page/204/ aria-label="Page 204" class=page-link role=button>204</a></li><li class=page-item><a href=/posts/page/205/ aria-label="Page 205" class=page-link role=button>205</a></li><li class=page-item><a href=/posts/page/204/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>