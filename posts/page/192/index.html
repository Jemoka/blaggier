<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnlp_semantics_timeline/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnlp_semantics_timeline/>NLP Semantics Timeline</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><ul><li>1990 static word embeddings</li><li>2003 neural language models</li><li>2008 multi-task learning</li><li>2015 attention</li><li>2017 transformer</li><li>2018 trainable contextual word embeddings + large scale pretraining</li><li>2019 prompt engineering</li></ul><h2 id=motivating-attention>Motivating Attention</h2><p>Given a sequence of embeddings: \(x_1, x_2, &mldr;, x_{n}\)</p><p>For each \(x_{i}\), the goal of attention is to <strong>produce a new embedding</strong> of each \(x_{i}\) named \(a_{i}\) based its dot product similarity with all other words that are before it.</p><p>Let&rsquo;s define:</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhchomsky/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhchomsky/>Noam Chomsky</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnon_deterministic_computation/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnon_deterministic_computation/>Non-Deterministic Computation</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>&mldr;building blocks of <a href=/posts/kbhnon_deterministic_turing_machines/>Non-deterministic Turing Machine</a>. Two transition functions:</p><p>\begin{equation}
\delta_{0}, \delta_{1} : Q \times \Gamma^{k} \to Q \times \Gamma^{k-1} \times \qty {L, R, S}^{k}
\end{equation}</p><p>At every point, apply both of these separate functions/branch on both. Some sequences lead to \(q_{\text{accept}}\), and some others lead to \(q_{\text{reject}}\).</p><p>We accept IFF exists any path accepts => we reject IFF all path rejects.</p><h2 id=why-np-is-awesome>why NP is awesome</h2><p>&ldquo;what a ridiculous model of computation!&rdquo;</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnondeterministic_finite_automata/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnondeterministic_finite_automata/>Non-deterministic Finite Automata</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhnondeterministic_finite_automata/>NFA</a> is a relaxation of <a href=/posts/kbhdeterministic_finite_automata/>DFA</a>, but which is allowed to make non-deterministic &ldquo;verified guesses&rdquo;.</p><p>this is basically a <a href=/posts/kbhdeterministic_finite_automata/>DFA</a>, but our new machine accepts a string if there exists <em>some path</em> that reaches <em>some accept state</em> from <em>some start state</em>.</p><p>at each state, we can have any number of out arrows for some letter \(\sigma \in \Sigma\), <strong>including</strong> for the empty string \(\varepsilon\). meaning we can move between states without doing anything.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnon_deterministic_space/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhnon_deterministic_space/>Non-Deterministic Space</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhnon_deterministic_space/>Non-Deterministic Space</a> is like <a href=/posts/kbhnon_deterministic_computation/>Non-Deterministic Computation</a> but now is space efficient.</p><h2 id=requirements>requirements</h2><p>We say \(A \in \text{NSPACE}\qty(s \qty(n))\) if \(\exists\) <a href=/posts/kbhnon_deterministic_turing_machines/>Non-deterministic Turing Machine</a> \(M\) which decides \(A\) such that \(M\) always uses \(O\qty(s \qty(n))\) space.</p><h2 id=additional-information>additional information</h2><p>See <a href=/posts/kbhnl/#nl>NL</a></p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/191/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/190/ aria-label="Page 190" class=page-link role=button>190</a></li><li class=page-item><a href=/posts/page/191/ aria-label="Page 191" class=page-link role=button>191</a></li><li class="page-item active"><a aria-current=page aria-label="Page 192" class=page-link role=button>192</a></li><li class=page-item><a href=/posts/page/193/ aria-label="Page 193" class=page-link role=button>193</a></li><li class=page-item><a href=/posts/page/194/ aria-label="Page 194" class=page-link role=button>194</a></li><li class=page-item><a href=/posts/page/193/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>