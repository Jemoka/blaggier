<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmake_models_go_brrr/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmake_models_go_brrr/>Make Models Go Brrr: Model Parallel Whisper Training</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Happy Monday friends.</p><p>The deliverable of the week was to make the a ASR model for Batchalign. Essentially, most copies of Whisper is pretty bad at Language Sample Analysis (LSA), because they mostly don&rsquo;t work in terms trying to actually capture the things that people doing LSA want to capture (disfluencies, stuttering, etc.). OpenAI even acknowledged in the paper that they filtered out the disfluencies from their gold transcript to prevent Whisper from writing down too much of them.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmap_restriction_operator/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmap_restriction_operator/>map restriction operator</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Suppose \(T \in \mathcal{L}(V)\), and \(U \subset V\), an <a href=/posts/kbhinvariant_subspace/>invariant subspace</a> under \(T\). Then:</p><p>\begin{equation}
T|_{U}(u) = Tu,\ \forall u \in U
\end{equation}</p><p>where \(T|_{U} \in \mathcal{L}(U)\)</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmapping_reduction/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmapping_reduction/>mapping reduction</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>A language \(A\) is mapping reducible to language \(B\), written as \(A \leq_{m} B\), if there is a computable function \(f: \Sigma^{*} \to \Sigma ^{ *}\) such that for every \(w\), \(w \in A \Leftrightarrow f(w) \in B\).</p><p>This is sometimes called a &ldquo;many-to-one&rdquo; reduction because often times you want to have multiple \(w\) mapping to the same \(f(w)\).</p><p>We remember this as &ldquo;A is weaker (&ldquo;not stronger&rdquo;) than B&rdquo;; or &ldquo;A is reducable to B&rdquo;</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmapreduce/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmapreduce/>MapReduce</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhmapreduce/>MapReduce</a> is an <a href=/posts/kbhdistributed_algorithum/>distributed algorithm</a>.</p><figure><img src=/ox-hugo/2023-07-31_11-58-49_screenshot.png></figure><p><a href=https://www.psc.edu/wp-content/uploads/2023/07/A-Brief-History-of-Big-Data.pdf>https://www.psc.edu/wp-content/uploads/2023/07/A-Brief-History-of-Big-Data.pdf</a></p><ul><li>Map: \((in\_key, in\_value) \Rightarrow list(out\_key, intermediate\_value)\).</li><li>Reduce:<ul><li>Group map outputs by \(out\_key\)</li><li>\((out\_key, list(intermediate\_value)) \Rightarrow list(out\_value)\)</li></ul></li></ul><h2 id=example-of-mapreduce--kbhmapreduce-dot-md>example of <a href=/posts/kbhmapreduce/>MapReduce</a></h2><p>Say, if you want to count word frequencies in a set of documents.</p><ul><li>Map: \((document\_name, document\_contents) \Rightarrow list(word, #\ occurrences)\)</li></ul><p>You can see that this can be distributed to multiple processors. You can have each processor count the word frequencies in a <em>single</em> document. We have now broken the contents into divide and conquerable groups.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmarkov_chain/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhmarkov_chain/>Markov Chain</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>A <a href=/posts/kbhmarkov_chain/>Markov Chain</a> is a chain of \(N\) states, with an \(N \times N\) transition matrix.</p><ol><li>at each step, we are in exactly one of those states</li><li>the matrix \(P_{ij}\) tells us \(P(j|i)\), the probability of going to state \(j\) given you are at state \(i\)</li></ol><p>And therefore:</p><p>\begin{equation}
\sum_{j=1}^{N} P_{ij} = 1
\end{equation}</p><h2 id=ergotic-markov-chain>Ergotic Markov Chain</h2><p>a markov chain is <a href=#ergotic-markov-chain>Ergotic</a> if&mldr;</p><ol><li>you have a path from any one state to any other</li><li>for any start state, after some time \(T_0\), the probability of being in any state at any \(T > T_0\) is non-zero</li></ol><p>Every <a href=#ergotic-markov-chain>Ergotic Markov Chain</a> has a long-term visit rate:</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/166/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/165/ aria-label="Page 165" class=page-link role=button>165</a></li><li class=page-item><a href=/posts/page/166/ aria-label="Page 166" class=page-link role=button>166</a></li><li class="page-item active"><a aria-current=page aria-label="Page 167" class=page-link role=button>167</a></li><li class=page-item><a href=/posts/page/168/ aria-label="Page 168" class=page-link role=button>168</a></li><li class=page-item><a href=/posts/page/169/ aria-label="Page 169" class=page-link role=button>169</a></li><li class=page-item><a href=/posts/page/168/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>