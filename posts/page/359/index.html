<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhvector_space/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhvector_space/>vector space</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>A <a href=/posts/kbhvector_space/>vector space</a> is an object between a <a href=/posts/kbhfield/>field</a> and a <a href=/posts/kbhgroup/>group</a>; it has two ops&mdash;addition and scalar multiplication. Its not quite a <a href=/posts/kbhfield/>field</a> and its more than a <a href=/posts/kbhgroup/>group</a>.</p><h2 id=constituents>constituents</h2><ul><li>A set \(V\)</li><li>An <a href=/posts/kbhadding/>addition</a> on \(V\)</li><li>An <a href=/posts/kbhscalar_multiplication/>scalar multiplication</a> on \(V\)</li></ul><p>such that&mldr;</p><h2 id=requirements>requirements</h2><ul><li><a href=/posts/kbhcommutivity/>commutativity</a> in add.: \(u+v=v+u\)</li><li><a href=/posts/kbhassociative/>associativity</a> in add. and mult.: \((u+v)+w=u+(v+w)\); \((ab)v=a(bv)\): \(\forall u,v,w \in V\) and \(a,b \in \mathbb{F}\)</li><li><a href=/posts/kbhdistributivity/>distributivity</a>: goes both ways \(a(u+v) = au+av\) AND!! \((a+b)v=av+bv\): \(\forall a,b \in \mathbb{F}\) and \(u,v \in V\)</li><li><a href=/posts/kbhadditive_identity/>additive identity</a>: \(\exists 0 \in V: v+0=v \forall v \in V\)</li><li><a href=/posts/kbhinverses/>additive inverse</a>: \(\forall v \in V, \exists w \in V: v+w=0\)</li><li><a href=/posts/kbhmultiplicative_identity/>multiplicative identity</a>: \(1v=v \forall v \in V\)</li></ul><h2 id=additional-information>additional information</h2><ul><li>Elements of a <a href=/posts/kbhvector_space/>vector space</a> are called <a href=/posts/kbhvector/>vector</a>s or <a href=/posts/kbhvector/>point</a>s.</li></ul><h3 id=vector-space-over-fields>vector space &ldquo;over&rdquo; fields</h3><p><a href=/posts/kbhscalar_multiplication/>Scalar multiplication</a> is not in the set \(V\); instead, &ldquo;scalars&rdquo; \(\lambda\) come from this magic faraway land called \(\mathbb{F}\). The choice of \(\mathbb{F}\) for each vector space makes it different; so, when precision is needed, we can say that a vector space is &ldquo;over&rdquo; some \(\mathbb{F}\) which contributes its scalars.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhcraintech/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhcraintech/>VFUA</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=this-is-worse>this is worse</h2></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhvgg/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhvgg/>VGG</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhvggish/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhvggish/>VGGish</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhvggish/>VGGish</a> is <a href=/posts/kbhvgg/>VGG</a>, ish. <a href=/posts/kbhvggish/>VGGish</a> is a network based on <a href=/posts/kbhvgg/>VGG</a> which is pretrained on the audio-feature-extraction task.</p><figure><img src=/ox-hugo/2022-06-23_23-29-00_screenshot.png></figure></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhpriors/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhpriors/>Video Generation with Learned Priors</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=visual-prediction-task>visual prediction task</h2><p>Given \(n\) frames of video \(x_{1}, &mldr;, x_{n}\), predict \(T\) subsequent frames \(x_{n+1}&mldr; x_{n+T}\).</p><h2 id=action-conditioned-prediction-network>Action Conditioned Prediction Network</h2><p>Visual prediction task. Two inputs:</p><ol><li>taken action</li><li>image</li></ol><p>Predict the next \(t\) frame. Challenge! What is the action? Predicting the action is not super easy.</p><h2 id=rafi>RAFI</h2><p>Conditional Flow Matching with Video Generation.</p><p><a href=https://arxiv.org/pdf/2406.14436>https://arxiv.org/pdf/2406.14436</a></p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/358/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/357/ aria-label="Page 357" class=page-link role=button>357</a></li><li class=page-item><a href=/posts/page/358/ aria-label="Page 358" class=page-link role=button>358</a></li><li class="page-item active"><a aria-current=page aria-label="Page 359" class=page-link role=button>359</a></li><li class=page-item><a href=/posts/page/360/ aria-label="Page 360" class=page-link role=button>360</a></li><li class=page-item><a href=/posts/page/361/ aria-label="Page 361" class=page-link role=button>361</a></li><li class=page-item><a href=/posts/page/360/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>