<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_2_c/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_2_c/>Axler 2.C</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>Because <a href=/posts/kbhlength_of_basis_doesn_t_depend_on_basis/>Length of Basis Doesn&rsquo;t Depend on Basis</a>, we defined <a href=/posts/kbhdimension/>dimension</a> as the same, shared length of <a href=/posts/kbhbasis/>basis</a> in a <a href=/posts/kbhvector_space/>vector space</a></li><li>We shown that lists of the right length (i.e. dim that space) that is <em>either</em> <a href=/posts/kbhdimension/#spanning-list-of-length-of-dim-v-are-a-basis-of-v>spanning</a> or <a href=/posts/kbhdimension/#linearly-independent-list-of-length-dim-v-are-a-basis-of-v>linearly independent</a> must be a basis&mdash;&ldquo;half is good enough&rdquo; theorems</li><li>we also shown that \(dim(U_1+U_2) = dim(U_1)+dim(U_2) - dim(U_1 \cap U_2)\): <a href=/posts/kbhsum_of_subsets/#id-07b04334-5ae7-457c-bc3e-92feed8fc2cc-dimension-of-sums>dimension of sums</a></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhdimension/>dimension</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhlength_of_basis_doesn_t_depend_on_basis/>Length of Basis Doesn&rsquo;t Depend on Basis</a></li><li>lists of right length are <a href=/posts/kbhbasis/>basis</a><ul><li><a href=/posts/kbhdimension/#linearly-independent-list-of-length-dim-v-are-a-basis-of-v>linearly independent list of length dim V are a basis of V</a></li><li><a href=/posts/kbhdimension/#spanning-list-of-length-of-dim-v-are-a-basis-of-v>spanning list of length of dim V are a basis of V</a></li></ul></li><li><a href=/posts/kbhsum_of_subsets/#id-07b04334-5ae7-457c-bc3e-92feed8fc2cc-dimension-of-sums>dimension of sums</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>Example 2.41: why is it that \(\dim U \neq 4\)? We only know that \(\dim \mathcal{P}_{3}(\mathbb{R}) = 4\), and \(\dim U \leq 4\). Is it because \(U\) (i.e. <a href=/posts/kbhbasis/>basis</a> of \(U\) doesn&rsquo;t <a href=/posts/kbhspan/>span</a> the polynomial) is strictly a subset of \(\mathcal{P}_{3}(\mathbb{R})\), so there must be <em>some</em> extension needed?</del> because we know that \(U\) isn&rsquo;t all of \(\mathcal{P}_{3}\).</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_a/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_a/>Axler 3.A</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>OMGOMGOMG its <em>Linear Maps</em> time! &ldquo;One of the key definitions in linear algebra.&rdquo;</p><h2 id=key-sequence>Key Sequence</h2><ul><li>We define these new-fangled functions called <a href=/posts/kbhlinear_map/>Linear Maps</a>, which obey \(T(u+v) = Tu+Tv\) and \(T(\lambda v) = \lambda Tv\)</li><li>We show that the set of all linear maps between two <a href=/posts/kbhvector_space/>vector space</a>s \(V,W\) is denoted \(\mathcal{L}(V,W)\); and, in fact, by defining <a href=/posts/kbhadding/>addition</a> and <a href=/posts/kbhscalar_multiplication/>scalar multiplication</a> of <a href=/posts/kbhlinear_map/>Linear Map</a>s in the way you&rsquo;d expect, \(\mathcal{L}(V,W)\) is a <a href=/posts/kbhvector_space/>vector space</a>!<ul><li>this also means that we can use effectively the \(0v=0\) proof to show that <a href=/posts/kbhlinear_map/#linear-maps-take-0-to-0>linear maps take \(0\) to \(0\)</a></li></ul></li><li>we show that <a href=/posts/kbhlinear_map/>Linear Map</a>s can be defined uniquely by <a href=/posts/kbhbasis_of_domain/>where it takes the basis of a vector space</a>; in fact, there exists a <a href=/posts/kbhlinear_map/>Linear Map</a> to take the <a href=/posts/kbhbasis/>basis</a> <em>anywhere</em> you want to go!</li><li>though this doesn&rsquo;t usually make sense, we call the &ldquo;composition&rdquo; operation on <a href=/posts/kbhlinear_map/>Linear Map</a>s their &ldquo;product&rdquo; and show that this product is <a href=/posts/kbhassociative/>associative</a>, <a href=/posts/kbhdistributivity/>distributive</a>, and has an <a href=/posts/kbhidentity/>identity</a></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhlinear_map/>Linear Map</a> &mdash; additivity (adding &ldquo;distributes&rdquo;) and homogeneity (scalar multiplication &ldquo;factors&rdquo;)<ul><li><a href=/posts/kbhlinear_map/#mathcal-l--v-w>\(\mathcal{L}(V,W)\)</a></li><li><a href=/posts/kbhlinear_map/#any-map-from-mathbb-f-n-to-mathbb-f-m>any polynomial map from Fn to Fm is a linear map</a></li><li><a href=/posts/kbhlinear_map/#addition-and-scalar-multiplication-on-mathcal-l--v-w>addition and scalar multiplication on \(\mathcal{L}(V,W)\)</a>; and, as a bonus, \(\mathcal{L}(V,W)\) a <a href=/posts/kbhvector_space/>vector space</a>!</li><li>naturally (almost by the same \(0v=0\) proof), <a href=/posts/kbhlinear_map/#linear-maps-take-0-to-0>linear maps take \(0\) to \(0\)</a></li></ul></li><li><a href=/posts/kbhproduct_of_linear_maps/>Product of Linear Maps</a> is just composition. These operations are:<ul><li>associative</li><li>distributive</li><li>has an identity</li></ul></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li>technically a result: <a href=/posts/kbhlinear_map/#any-map-from-mathbb-f-n-to-mathbb-f-m>any polynomial map from Fn to Fm is a linear map</a></li><li><a href=/posts/kbhbasis_of_domain/>basis of domain of linear maps uniquely determines them</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li>why does the second part of the <a href=/posts/kbhbasis_of_domain/>basis of domain</a> proof make it unique?</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_b/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_b/>Axler 3.B</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined the <a href=/posts/kbhnull_space/>null space</a> and <a href=/posts/kbhinjectivity/>injectivity</a><ul><li>from that, we showed that <a href=/posts/kbhinjectivity/#injectivity-implies-that-id-767a441d-4931-4fad-aa8e-c6b001e8b507-null-space-is-0>injectivity IFF implies that null space is \(\{0\}\)</a>, essentially because if \(T0=0\) already, there cannot be another one that also is taken to \(0\) in an <a href=/posts/kbhinjectivity/>injective</a> function</li></ul></li><li>we defined <a href=/posts/kbhrange/>range</a> and <a href=/posts/kbhsurjectivity/>surjectivity</a></li><li>we showed that these concepts are strongly related by the <a href=/posts/kbhfundamental_theorem_of_linear_maps/>fundamental theorem of linear maps</a>: if \(T \in \mathcal{L}(V,W)\), then \(\dim V = \dim null\ T + \dim range\ T\)</li><li>from the fundamental theorem, we showed the somewhat intuitive pair about the sizes of maps: <a href=/posts/kbhlinear_map/#map-to-smaller-space-is-not-id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injective>map to smaller space is not injective</a>, <a href=/posts/kbhlinear_map/#map-to-bigger-space-is-not-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjective>map to bigger space is not surjective</a></li><li>we then applied that result to show results about <a href=/posts/kbhhomogeneity/>homogeneous</a> systems<ul><li><a href=/posts/kbhhomogeneity/#id-f57b638c-b8c9-4c88-b02f-9cd0ed47c51e-homogenous-system-with-more-variables-than-equations-has-nonzero-solutions>homogenous system with more variables than equations has nonzero solutions</a></li><li><a href=/posts/kbhhomogeneity/#in-id-f57b638c-b8c9-4c88-b02f-9cd0ed47c51e-homogenous-system-with-more-equations-than-variables-has-no-solutions-for-an-arbitrary-set-of-constants>inhomogenous system with more equations than variables has no solutions for an arbitrary set of constants</a></li></ul></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhnull_space/>null space</a><ul><li><a href=/posts/kbhinjectivity/>injectivity</a></li></ul></li><li><a href=/posts/kbhrange/>range</a><ul><li><a href=/posts/kbhsurjectivity/>surjectivity</a></li></ul></li><li><a href=/posts/kbhhomogeneity/>homogeneous system</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhnull_space/#the-null-space-is-a-id-345c37fa-5d4c-44e9-ad03-2fe7e5a37224-subspace-of-the-domain>the null space is a subspace of the domain</a></li><li><a href=/posts/kbhinjectivity/#injectivity-implies-that-id-767a441d-4931-4fad-aa8e-c6b001e8b507-null-space-is-0>injectivity IFF implies that null space is \(\{0\}\)</a></li><li>the <a href=/posts/kbhfundamental_theorem_of_linear_maps/>fundamental theorem of linear maps</a></li><li>&ldquo;sizes&rdquo; of maps<ul><li><a href=/posts/kbhlinear_map/#map-to-smaller-space-is-not-id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injective>map to smaller space is not injective</a></li><li><a href=/posts/kbhlinear_map/#map-to-bigger-space-is-not-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjective>map to bigger space is not surjective</a></li></ul></li><li>solving systems of equations:<ul><li><a href=/posts/kbhhomogeneity/#id-f57b638c-b8c9-4c88-b02f-9cd0ed47c51e-homogenous-system-with-more-variables-than-equations-has-nonzero-solutions>homogenous system with more variables than equations has nonzero solutions</a></li><li><a href=/posts/kbhhomogeneity/#in-id-f57b638c-b8c9-4c88-b02f-9cd0ed47c51e-homogenous-system-with-more-equations-than-variables-has-no-solutions-for-an-arbitrary-set-of-constants>inhomogenous system with more equations than variables has no solutions for an arbitrary set of constants</a></li></ul></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>&ldquo;To prove the inclusion in the other direction, suppose v 2 null T.&rdquo; for 3.16; what is the <em>first</em> direction?</del> maybe nothing maps to \(0\)</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_c/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_c/>Axler 3.C</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhmatricies/>matricies</a>!!!!</p><h2 id=key-sequence>Key Sequence</h2><ul><li><a href=/posts/kbhmatricies/>matricies</a> exist, you can <a href=/posts/kbhmatricies/#sums-and-scalar-multiplication-of-id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies>add them, scalarly multiply them</a>, and <a href=/posts/kbhmatrix_multiplication/>actually multiply them</a></li><li>they <a href=/posts/kbhmatricies/#matrix-of-id-17f3b01c-4945-4268-8da4-9887d960596b-linear-map>can represent Linear Maps by showing where they take basis</a></li><li>unsurprisingly, the <a href=/posts/kbhmatricies/#mathbb-f-m-n>set of matricies of a shape is a vector space</a></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhmatricies/>matricies</a><ul><li><a href=/posts/kbhmatricies/#matrix-of-id-17f3b01c-4945-4268-8da4-9887d960596b-linear-map>matrix of Linear Map</a></li><li><a href=/posts/kbhmatricies/#sums-and-scalar-multiplication-of-id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies>matrix addition and scalar multiplications</a></li><li><a href=/posts/kbhmatrix_multiplication/>matrix multiplication</a></li></ul></li><li><a href=/posts/kbhmatricies/#mathbb-f-m-n>\(\mathbb{F}^{m,n}\)</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhmatricies/#sums-and-scalar-multiplication-of-id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies>sums and scalar multiplication of matricies</a>, and why they work to represent <a href=/posts/kbhlinear_map/>Linear Map</a>s</li><li><a href=/posts/kbhmatricies/#mathbb-f-m-n>\(\mathbb{F}^{m,n}\) is a vector space</a></li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><p>its literally <a href=/posts/kbhmatricies/>matricies</a></p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_d/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_d/>Axler 3.D</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhisomorphism/>isomorphism</a>s. Somebody&rsquo;s new favourite word since last year.</p><h2 id=key-sequence>Key Sequence</h2><ul><li>we showed that a <a href=/posts/kbhinvertability/#linear-map-inverse-is-unique>linear map&rsquo;s inverse is unique</a>, and so named the inverse \(T^{-1}\)</li><li>we then showed an important result, that <a href=/posts/kbhinvertability/#id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injectivity-and-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjectivity-implies-id-ff05739c-6e70-46ba-9d56-0958ef847f57-invertability>injectivity and surjectivity implies invertability</a></li><li>this property allowed us to use <a href=/posts/kbhinvertability/>invertable</a> maps to define <a href=/posts/kbhisomorphism/>isomorphic</a> spaces, naming the <a href=/posts/kbhinvertability/>invertable</a> map between them as the <a href=/posts/kbhisomorphism/>isomorphism</a><ul><li>we see that <a href=/posts/kbhisomorphism/#two-vector-spaces-are-isomorphic-iff-they-have-the-same-dimension>having the same dimension is enough to show invertability (IFF)</a>, because we can use <a href=/posts/kbhbasis_of_domain/>basis of domain</a> to map the <a href=/posts/kbhbasis/>basis</a> of one space to another</li><li>we then use that property to establish that <a href=/posts/kbhisomorphism/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies-and-id-17f3b01c-4945-4268-8da4-9887d960596b-linear-map-s-from-the-right-id-07b04334-5ae7-457c-bc3e-92feed8fc2cc-dimension-s-are-id-3f5ba3a5-15d4-4b58-99de-09eb1e4713cb-isomorphic>matricies and linear maps have an isomorphism between them</a>: namely, the matrixify operator \(\mathcal{M}\).</li><li>this <a href=/posts/kbhisomorphism/>isomorphism</a> allow us to show that the <a href=/posts/kbhdimension/>dimension</a> of a set of <a href=/posts/kbhlinear_map/>Linear Map</a>s is the product of the <a href=/posts/kbhdimension/>dimension</a>s of their domain and codomain (that <a href=/posts/kbhisomorphism/#dim-mathcal-l--v-w----dim-v----dim-w>\(\dim \mathcal{L}(V,W) = (\dim V)(\dim W)\)</a>)</li></ul></li><li>We then, for some unknown reason, decided that right this second we gotta define <a href=/posts/kbhmatricies/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matrix-of-a-vector>matrix of a vector</a>, and that <a href=/posts/kbhmatrix_multiplication/#linear-maps-are-like-matrix-multiplication>linear map applications are like matrix multiplication</a> because of it. Not sure how this relates</li><li>finally, we defined a <a href=/posts/kbhlinear_map/>Linear Map</a> from a space to itself as an <a href=/posts/kbhoperator/>operator</a><ul><li>we finally show an important result that, despite not being true for <a href=/posts/kbhfinite_dimensional_vector_space/>infinite-demensional vector space</a>, <a href=/posts/kbhoperator/#id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injectivity-is-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjectivity-in-id-4ed27ed5-4edc-4ef4-afd7-9b8e3bcd9b96-finite-dimensional-id-36e84a46-76f1-481e-b031-8ab2f0da0aa8-operator-s>injectivity is surjectivity in finite-dimensional operators</a></li></ul></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhinvertability/>invertability</a></li><li><a href=/posts/kbhisomorphism/>isomorphism</a> + <a href=/posts/kbhisomorphism/>isomorphic</a> <a href=/posts/kbhvector_space/>vector space</a>s</li><li><a href=/posts/kbhmatricies/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matrix-of-a-vector>matrix of a vector</a></li><li><a href=/posts/kbhoperator/>operator</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhinvertability/#linear-map-inverse-is-unique>linear map inverse is unique</a></li><li><a href=/posts/kbhinvertability/#id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injectivity-and-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjectivity-implies-id-ff05739c-6e70-46ba-9d56-0958ef847f57-invertability>injectivity and surjectivity implies invertability</a></li><li><a href=/posts/kbhisomorphism/#two-vector-spaces-are-isomorphic-iff-they-have-the-same-dimension>two vector spaces are isomorphic IFF they have the same dimension</a></li><li><a href=/posts/kbhisomorphism/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies-and-id-17f3b01c-4945-4268-8da4-9887d960596b-linear-map-s-from-the-right-id-07b04334-5ae7-457c-bc3e-92feed8fc2cc-dimension-s-are-id-3f5ba3a5-15d4-4b58-99de-09eb1e4713cb-isomorphic>matricies and Linear Maps from the right dimensions are isomorphic</a></li><li><a href=/posts/kbhisomorphism/#dim-mathcal-l--v-w----dim-v----dim-w>\(\dim \mathcal{L}(V,W) = (\dim V)(\dim W)\)</a></li><li>\(\mathcal{M}(T)_{.,k} = \mathcal{M}(Tv_{k})\), a result of how everything is defined (see <a href=/posts/kbhmatricies/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matrix-of-a-vector>matrix of a vector</a>)<ul><li>&ldquo;each column of a <a href=/posts/kbhmatricies/>matrix</a> represents where each of the <a href=/posts/kbhbasis/>basis</a> of the input gets taken to&rdquo;</li><li>So applying a vector to a matrix shows the linear combination of what where the basis sent</li></ul></li><li><a href=/posts/kbhmatrix_multiplication/#linear-maps-are-like-matrix-multiplication>linear maps are like matrix multiplication</a></li><li><a href=/posts/kbhoperator/#id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injectivity-is-id-1af529ce-e2fb-43a4-8f13-aee1dc743b5f-surjectivity-in-id-4ed27ed5-4edc-4ef4-afd7-9b8e3bcd9b96-finite-dimensional-id-36e84a46-76f1-481e-b031-8ab2f0da0aa8-operator-s>injectivity is surjectivity in finite-dimensional operators</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>why doesn&rsquo;t axler just say the &ldquo;<a href=/posts/kbhbasis_of_domain/>basis of domain</a>&rdquo; directly (i.e. he did a lin comb instead) for the second direction for the <a href=/posts/kbhisomorphism/#two-vector-spaces-are-isomorphic-iff-they-have-the-same-dimension>two vector spaces are isomorphic IFF they have the same dimension</a> proof?</del> because the next steps for <a href=/posts/kbhspan/#spans>spanning</a> (<a href=/posts/kbhsurjectivity/>surjectivity</a>) and <a href=/posts/kbhlinear_independence/>linear independence</a> (<a href=/posts/kbhinjectivity/>injectivity</a>) is made more obvious</li><li><del>clarify the <a href=/posts/kbhisomorphism/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matricies-and-id-17f3b01c-4945-4268-8da4-9887d960596b-linear-map-s-from-the-right-id-07b04334-5ae7-457c-bc3e-92feed8fc2cc-dimension-s-are-id-3f5ba3a5-15d4-4b58-99de-09eb1e4713cb-isomorphic>matricies and Linear Maps from the right dimensions are isomorphic</a> proof</del></li><li><del>what is the &ldquo;multiplication by \(x^{2}\)&rdquo; <a href=/posts/kbhoperator/>operator</a>?</del> literally multiplying by \(x^{2}\)</li><li><del>how does the <a href=/posts/kbhmatricies/#id-7a09bc5f-6de2-485f-8c29-b94999299cc6-matrix-of-a-vector>matrix of a vector</a> detour relate to the content before and after? I suppose an <a href=/posts/kbhisomorphism/>isomorphism</a> exists but it isn&rsquo;t explicitly used in the <a href=/posts/kbhmatrix_multiplication/#linear-maps-are-like-matrix-multiplication>linear maps are like matrix multiplication</a> proof, which is the whole point</del> because we needed to close the loop of being able to linear algebra with <a href=/posts/kbhmatricies/>matricies</a> completely, which we didn&rsquo;t know without the <a href=/posts/kbhisomorphism/>isomorphism</a> between matricies and maps</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/33/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/32/ aria-label="Page 32" class=page-link role=button>32</a></li><li class=page-item><a href=/posts/page/33/ aria-label="Page 33" class=page-link role=button>33</a></li><li class="page-item active"><a aria-current=page aria-label="Page 34" class=page-link role=button>34</a></li><li class=page-item><a href=/posts/page/35/ aria-label="Page 35" class=page-link role=button>35</a></li><li class=page-item><a href=/posts/page/36/ aria-label="Page 36" class=page-link role=button>36</a></li><li class=page-item><a href=/posts/page/35/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>