<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhtodo_lists/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhtodo_lists/>Why is building a to-do list app so darn hard?</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Why are <a href=/posts/kbhtodo_lists/>Todo Lists</a> (a.k.a. personal productivity systems) so hard to build well?</p><p>I&rsquo;m genuinely curious. I was listening to the last episode of <a href=https://www.relay.fm/cortex/>Cortex</a>, and one of the hosts (CGP Grey) brought up a similar point regarding personal productivity platforms. OmniFocus, the reigning champion of the industry for professionals looking for a deeply customized system, has been staggering in their ability to ship the next version of their application. Much of the market consists of various different packagings of the same offering. Grey&rsquo;s thesis of these platforms essentially boils down to this:</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhwindow_based_co_occurance/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhwindow_based_co_occurance/>window-based co-occurance</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhwindow_based_co_occurance/>window-based co-occurance</a> is a matrix whereby we increment the value where each row is the center word, and each column is the number of occurrences of that other word next to a window of that word.</p><p>This approach is fine (not great), but if your vocabulary is HUGE, your word vectors will be exactly that length&mdash;bad. Therefore, we take this matrix and we <a href=/posts/kbhsingular_value_decomposition/>SVD</a> it; then, we chop off the smaller singular values to create a low dimensional approximation of our matrix.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhwindows_fat/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhwindows_fat/>Windows FAT</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p><a href=/posts/kbhlinked_files/>linked files</a> architecture for <a href=/posts/kbhfilesystem/>filesystem</a>, but it caches the file links in memory when the OS is running.</p><h2 id=problems>problems</h2><ul><li>data is <strong>still</strong> scattered across the disk</li><li>we had to construct the file allocation table</li><li>though its must faster because jumping to the middle of the file is now in memory, we are still doing O(n) search for a specific sub part</li></ul></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhword_normalization/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhword_normalization/>Word Normalization</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Pay attention to:</p><ol><li>cases (all letters to lower case?)</li><li><a href=/posts/kbhtokenization/>lemma</a>tization</li></ol><p>This is often done with <a href=/posts/kbhmorphological_parsing/>morphological parsing</a>, for instance, you can try <a href=/posts/kbhmorphological_parsing/#stemming>stemming</a>.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhword2vec/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhword2vec/>word2vec</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>we will train a classifier on a binary prediction task: &ldquo;is context words \(c_{1:L}\) likely to show up near some target word \(W_0\)?&rdquo;</p><p>We estimate the probability that \(w_{0}\) occurs within this window based on the product of the probabilities of the similarity of the embeddings between each context word and the target word.</p><ul><li>we have a corpus of text</li><li>each word is represented by a <a href=/posts/kbhvector/>vector</a></li><li>go through each position \(t\) in the text, which has a center word \(c\) and set of context words \(o \in O\)</li><li>use similarity of word vectors \(c\) and \(o\) to calculate \(P(o|c)\)</li></ul><p>Meaning, we want to devise a model which can predict high probabilities \(P(w_{t-n}|w_{t})\) for small \(n\) and low probabilities for large \(n\)</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/363/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/362/ aria-label="Page 362" class=page-link role=button>362</a></li><li class=page-item><a href=/posts/page/363/ aria-label="Page 363" class=page-link role=button>363</a></li><li class="page-item active"><a aria-current=page aria-label="Page 364" class=page-link role=button>364</a></li><li class=page-item><a href=/posts/page/365/ aria-label="Page 365" class=page-link role=button>365</a></li><li class=page-item><a href=/posts/page/366/ aria-label="Page 366" class=page-link role=button>366</a></li><li class=page-item><a href=/posts/page/365/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>