<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_e/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_e/>Axler 3.E</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>No idea why this is so long!!!</p><h2 id=key-sequence>Key Sequence</h2><p>Firehose of a chapter.</p><ul><li>We first began an unrelated exploration in <a href=/posts/kbhproduct_of_vector_spaces/>Product of Vector Space</a>s (&ldquo;tuples&rdquo;):<ul><li>we show that the <a href=/posts/kbhproduct_of_vector_spaces/>Product of Vector Space</a>s is a <a href=/posts/kbhvector_space/>vector space</a></li><li>because you can build a list out of zeroing every element except each one on each <a href=/posts/kbhbasis/>basis</a> of each element of the tuple sequentially, we learned that the <a href=/posts/kbhproduct_of_vector_spaces/#dimension-of-the-id-a45b05c0-3e01-4c27-bc3b-543ff3606c66-product-of-vector-space-s-is-the-sum-of-the-spaces-dimension>dimension of the Product of Vector Spaces is the sum of the spaces&rsquo; dimension</a>.</li><li>we defined the product-to-sum map \(\Gamma\)<ul><li><a href=/posts/kbhproduct_summation_map/#u-1-plus-dots-plus-u-m-is-a-id-4e586014-c91f-4d52-98bb-a2fe11a75007-direct-sum-id-fddf0648-91ea-4c5b-8298-fa0a30637cb7-iff-gamma-is-id-e3ff3c90-e719-4c5b-afc4-efcec3169fb2-injective>\(U_1 + \dots + U_{m}\) is a direct sum IFF \(\Gamma\) is injective</a></li><li>and, as a result, <a href=/posts/kbhproduct_summation_map/#u-1-plus-dots-plus-u-m-is-a-id-4e586014-c91f-4d52-98bb-a2fe11a75007-direct-sum-iff-dim--u-1-plus-dots-plus-u-m--dim-u-1-plus-dots-plus-dim-u-m>\(U_1 + \dots + U_{m}\) is a direct sum IFF \(\dim (U_1 + \dots + U_{m}) = \dim U_1 + \dots + \dim U_{m}\)</a></li></ul></li></ul></li><li>We then tackled the fun part of this chapter, which is <a href=/posts/kbhparallel_linear_algebra/>affine subset</a>s, <a href=/posts/kbhparallel_linear_algebra/>parallel</a> structures, <a href=/posts/kbhquotient_space/>quotient space</a>s, <a href=/posts/kbhquotient_map/>quotient map</a> (<a href=/posts/kbhparallel_linear_algebra/>affine subset</a>ification maps)<ul><li>we learned an important and useful result that <a href=/posts/kbhparallel_linear_algebra/#two-id-4c9e8fea-cd23-4a41-b85e-bb5be3867c96-affine-subset-s-id-4c9e8fea-cd23-4a41-b85e-bb5be3867c96-parallel-to-u-are-either-equal-or-disjoint>two affine subsets parallel to \(U\) are either equal or disjoint</a> (\(v-w \in U\) means \(v+U = w+U\) means \(v+U \cap w+U \neq \emptyset\), means the first thing)</li><li>we defined the <a href=/posts/kbhquotient_space/#operations-on-id-53548f85-b3c8-42ce-81e7-9016ed7bd280-quotient-space>operations on quotient space</a>, and showed that <a href=/posts/kbhquotient_space/#id-53548f85-b3c8-42ce-81e7-9016ed7bd280-quotient-space-operations-behave-uniformly-on-equivalent-id-4c9e8fea-cd23-4a41-b85e-bb5be3867c96-affine-subset-s>quotient space operations behave uniformly on equivalent affine subsets</a>. This, and the usual closer proof, demonstrates that <a href=/posts/kbhquotient_space/>quotient space</a>s is a <a href=/posts/kbhvector_space/>vector space</a></li><li>with the help of the <a href=/posts/kbhparallel_linear_algebra/>affine subset</a>ification map (the <a href=/posts/kbhquotient_map/>quotient map</a> \(\pi\)), we show that the <a href=/posts/kbhquotient_space/#dimension-of-a-quotient-space-is-the-difference-between-dimensions-of-its-constituents>dimension of a quotient space is the difference between dimensions of its constituents</a> essentially by invoking <a href=/posts/kbhfundamental_theorem_of_linear_maps/>rank-nullity theorem</a> after knowing the fact that \(null\ \pi = U\) (because \(u+U\) is an <a href=/posts/kbhparallel_linear_algebra/>affine subset</a> that has not been shifted (think about a line moving along itself&mldr; it doesn&rsquo;t move))</li></ul></li><li>Then, and I&rsquo;m not quite sure why, we defined \(\widetilde{T}: V / null\ T \to W\), for some \(T: V\to W\), defined as \(\widetilde{T}(v+null\ T) = Tv\).<ul><li>We show that the map is <a href=/posts/kbhlinear_map/>Linear</a>, <a href=/posts/kbhinjectivity/>injective</a>, its range is \(range\ T\), and so it forms an <a href=/posts/kbhisomorphism/>isomorphism</a> between \(V / null\ T\) and \(range\ T\).</li></ul></li></ul><p>Here&rsquo;s something: <a href=/posts/kbhproducts_and_quotients_the_intuition/>products and quotients, the intuition</a></p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_3_f/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_3_f/>Axler 3.F</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>Because duality is fun and I&rsquo;m bored and <code>houjun-being-obtuse</code>.</p><h2 id=key-sequence>Key Sequence</h2><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhlinear_functional/>linear functional</a></li><li><a href=/posts/kbhdual_space/>dual space</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhdual_space/#dimension-of-dual-space-is-equivalent-to-the-original-space>dimension of dual space is equivalent to the original space</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><h2 id=interesting-factoids>Interesting Factoids</h2><p>Hello from onboard NH107! Or perhaps my next connecting flight, or from China.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_5_a/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_5_a/>Axler 5.A</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><p>EIGENSTUFF and <a href=/posts/kbhoperator/>OPERATOR</a>S! Invariant subspaces are nice.</p><p>Sometimes, if we can break the domain of a linear map down to its eigenvalues, we can understand what its doing on a component-wise level.</p><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined an <a href=/posts/kbhinvariant_subspace/>invariant subspace</a>, and gave a name to 1-D <a href=/posts/kbhinvariant_subspace/>invariant subspace</a>s: the span of <a href=/posts/kbheigenvalue/>eigenvector</a>s</li><li>we showed some <a href=/posts/kbheigenvalue/#properties-of-id-7d742b39-4a4a-4a9d-a55b-07e2030dfdeb-eigenvalue-s>properties of eigenvalues</a> and showed that a <a href=/posts/kbheigenvalue/#list-of-eigenvectors-are-id-45384b28-f1e3-4fb1-aeb2-21c875834744-linearly-independent>list of eigenvectors are linearly independent</a><ul><li>a correlate of this is that <a href=/posts/kbheigenvalue/#operators-on-finite-dimensional-v-has-at-most-dim-v-id-7d742b39-4a4a-4a9d-a55b-07e2030dfdeb-eigenvalue-s>operators on finite dimensional V has at most dim V eigenvalues</a></li></ul></li><li>finally, we defined <a href=/posts/kbhmap_restriction_operator/>map restriction operator</a> and <a href=/posts/kbhquotient_operator/>quotient operator</a>, and showed that they were well-defined</li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhinvariant_subspace/>invariant subspace</a><ul><li>conditions for <a href=/posts/kbhinvariant_subspace/#nontrivial-id-731fad15-1ec3-4619-8532-1290fefd3b89-invariant-subspace>nontrivial invariant subspace</a></li></ul></li><li><a href=/posts/kbheigenvalue/>eigenvalue</a>s + <a href=/posts/kbheigenvalue/>eigenvector</a>s + <a href=/posts/kbheigenspace/>eigenspace</a></li><li>two new operators: <a href=/posts/kbhmap_restriction_operator/>map restriction operator</a> and <a href=/posts/kbhquotient_operator/>quotient operator</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbheigenvalue/#properties-of-id-7d742b39-4a4a-4a9d-a55b-07e2030dfdeb-eigenvalue-s>properties of eigenvalues</a></li><li><a href=/posts/kbheigenvalue/#list-of-eigenvectors-are-id-45384b28-f1e3-4fb1-aeb2-21c875834744-linearly-independent>list of eigenvectors are linearly independent</a><ul><li><a href=/posts/kbheigenvalue/#eigenspaces-are-disjoint>eigenspaces are disjoint</a></li><li><a href=/posts/kbheigenvalue/#operators-on-finite-dimensional-v-has-at-most-dim-v-id-7d742b39-4a4a-4a9d-a55b-07e2030dfdeb-eigenvalue-s>operators on finite dimensional V has at most dim V eigenvalues</a></li></ul></li><li><a href=/posts/kbhquotient_operator/#id-84dca125-e64f-48d7-b71e-858ad5c3db6c-quotient-operator-is-well-defined>quotient operator is well-defined</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><pre tabindex=0><code class="language-Doesn't" data-lang="Doesn't"></code></pre></li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><p>&ldquo;<a href=/posts/kbheigenvalue/>eigenvalue</a>&rdquo; is sometimes called the &ldquo;characterizing value&rdquo; of a map</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_5_b/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_5_b/>Axler 5.B</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we began the chapter defining <a href=/posts/kbhraising_operators_to_powers/>\(T^m\)</a> (reminding ourselves the usual rules of \(T^{m+n} = T^{m}T^{n}\), \((T^{m})^{n} = T^{mn}\), and, for invertible maps, \(T^{-m} = (T^{-1})^{m}\)) and <a href=/posts/kbhpolynomial_operator/>\(p(T)\)</a>, wrapping copies of \(T\) into coefficients of a polynomial, and from those definitions showed that <a href=/posts/kbhpolynomial_operator/#id-fbaf420a-6345-417b-8016-a976e7b155be-polynomial-of-operator-is-commutative>polynomial of operator is commutative</a></li><li>we then used those results + <a href>fundamental theorem of algebra</a> to show that <a href=/posts/kbhoperators_on_complex_vector_spaces_have_an_eigenvalue/>operators on complex vector spaces have an eigenvalue</a></li><li>that previous, important result in hand, we then dove into <a href=/posts/kbhupper_triangular_matrix/>upper-triangular matricies</a><ul><li>specifically, we learned the <a href=/posts/kbhupper_triangular_matrix/#properties-of-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>properties of upper-triangular matrix</a>, that if \(v_1 &mldr; v_{n}\) is a <a href=/posts/kbhbasis/>basis</a> of \(V\) then \(\mathcal{M}(T)\) is <a href=/posts/kbhupper_triangular_matrix/>upper-triangular</a> if \(Tv_{j} \in span(v_1, &mldr; v_{j})\) for all \(j \leq n\); and, equivalently, \(T\) in <a href=/posts/kbhinvariant_subspace/>invariant</a> under the <a href=/posts/kbhspan/>span</a> of \(v_{j}\)</li><li>using that result, we show that <a href=/posts/kbhupper_triangular_matrix/#every-complex-operator-has-an-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>every complex operator has an upper-triangular matrix</a></li><li>using some neat tricks of algebra, we then establish that <a href=/posts/kbhupper_triangular_matrix/#operator-is-only-invertible-if-id-c38ed162-6861-420c-a812-6d25ac539ea9-diagonal-of-its-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix-is-nonzero>operator is only invertible if diagonal of its upper-triangular matrix is nonzero</a>, which seems awfully unmotivated until you learn that&mldr;</li><li><a href=/posts/kbhupper_triangular_matrix/#eigenvalues-of-a-map-are-the-entries-of-the-id-c38ed162-6861-420c-a812-6d25ac539ea9-diagonal-of-its-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>eigenvalues of a map are the entries of the diagonal of its upper-triangular matrix</a>, and that basically is a direct correlary from the <a href=/posts/kbhupper_triangular_matrix/>upper-triangular matrix</a> of \(T-\lambda I\)</li></ul></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhraising_operators_to_powers/>\(T^m\)</a></li><li><a href=/posts/kbhpolynomial_operator/>\(p(T)\)</a><ul><li>technically also <a href>product of polynomials</a></li></ul></li><li><a href=/posts/kbhmatricies/>matrix</a> of an <a href=/posts/kbhoperator/>operator</a><ul><li><a href=/posts/kbhmatricies/#diagonal>diagonal</a> of a matrix</li><li><a href=/posts/kbhupper_triangular_matrix/>upper-triangular matrix</a></li></ul></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbhpolynomial_operator/#p--z--to-p--t--is-a-linear-id-d782b5f7-29b5-4f70-a058-f15c0162cbef-function>\(p(z) \to p(T)\) is a linear function</a></li><li><a href=/posts/kbhpolynomial_operator/#id-fbaf420a-6345-417b-8016-a976e7b155be-polynomial-of-operator-is-commutative>polynomial of operator is commutative</a></li><li><a href=/posts/kbhoperators_on_complex_vector_spaces_have_an_eigenvalue/>operators on complex vector spaces have an eigenvalue</a></li><li><a href=/posts/kbhupper_triangular_matrix/#properties-of-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>properties of upper-triangular matrix</a></li><li><a href=/posts/kbhupper_triangular_matrix/#every-complex-operator-has-an-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>every complex operator has an upper-triangular matrix</a></li><li><a href=/posts/kbhupper_triangular_matrix/#operator-is-only-invertible-if-id-c38ed162-6861-420c-a812-6d25ac539ea9-diagonal-of-its-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix-is-nonzero>operator is only invertible if diagonal of its upper-triangular matrix is nonzero</a></li><li><a href=/posts/kbhupper_triangular_matrix/#eigenvalues-of-a-map-are-the-entries-of-the-id-c38ed162-6861-420c-a812-6d25ac539ea9-diagonal-of-its-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>eigenvalues of a map are the entries of the diagonal of its upper-triangular matrix</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li><del>why define the <a href=/posts/kbhmatricies/>matrix</a> of an <a href=/posts/kbhoperator/>operator</a> again??</del> just to stress that its square</li><li>for the second flavor of the proof that <a href=/posts/kbhupper_triangular_matrix/#every-complex-operator-has-an-id-af53dbd7-0421-4039-a9f9-9080ea6e1c42-upper-triangular-matrix>every complex operator has an upper-triangular matrix</a>, why is \(v_1 &mldr; v_{j}\) a <a href=/posts/kbhbasis/>basis</a> of \(V\)?</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><p>Its 12:18AM and I read this chapter for 5 hours. I also just got jumpscared by my phone notification. What&rsquo;s happening?</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_5_c/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhaxler_5_c/>Axler 5.C</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-sequence>Key Sequence</h2><ul><li>we defined an <a href=/posts/kbheigenspace/>eigenspace</a>, which is the space of all <a href=/posts/kbheigenvalue/>eigenvalue</a>s of a distinct <a href=/posts/kbheigenvalue/>eigenvector</a>, and show that<ul><li><a href=/posts/kbheigenvalue/#eigenspaces-are-disjoint>they form a direct sum</a> to the whole space</li><li>and, as a correlate to how <a href=/posts/kbhdirect_sum/>direct sum</a>s are kind of like disjoint sets, we have the <a href=/posts/kbheigenspace/#dimension-of-sum-of-eigenspaces-is-smaller-than-or-equal-to-the-dimension-of-the-whole-space>perhaps expected result of dimension</a>, that the sum of the <a href=/posts/kbheigenspace/>eigenspace</a>&rsquo; dimensions must be smaller than or equal than that of \(V\)</li></ul></li><li>we defined a <a href=/posts/kbhdiagonal_matrix/>Diagonal Matrix</a>, which by its structure + calculation can be shown to require that it is formed by a <a href=/posts/kbhbasis/>basis</a> of <a href=/posts/kbheigenvalue/>eigenvalue</a>s<ul><li>and from there, and the properties of <a href=/posts/kbheigenspace/>eigenspace</a>s above, we deduce <a href=/posts/kbhdiagonal_matrix/#properties-of-diagonal-matrices>some conditions equal to diagonalizability</a></li><li>a direct correlary of the last point (perhaps more straightforwardly intuited by just lining <a href=/posts/kbheigenvalue/>eigenvalue</a> up diagonally in a matrix) is that <a href=/posts/kbhdiagonal_matrix/#enough-eigenvalues-implies-diagonalizability>enough eigenvalues implies diagonalizability</a></li></ul></li></ul><h2 id=new-definitions>New Definitions</h2><ul><li><a href=/posts/kbhdiagonal_matrix/>diagonal matrix</a><ul><li><a href=/posts/kbhdiagonal_matrix/#properties-of-diagonal-matrices>properties of diagonal matrices</a></li></ul></li><li><a href=/posts/kbheigenspace/>eigenspace</a></li></ul><h2 id=results-and-their-proofs>Results and Their Proofs</h2><ul><li><a href=/posts/kbheigenvalue/#eigenspaces-are-disjoint>eigenspaces are a direct sum</a></li><li><a href=/posts/kbheigenspace/#dimension-of-sum-of-eigenspaces-is-smaller-than-or-equal-to-the-dimension-of-the-whole-space>dimension of sum of eigenspaces is smaller than or equal to the dimension of the whole space</a></li><li><a href=/posts/kbhdiagonal_matrix/#properties-of-diagonal-matrices>conditions equal to diagonalizability</a></li><li><a href=/posts/kbhdiagonal_matrix/#enough-eigenvalues-implies-diagonalizability>enough eigenvalues implies diagonalizability</a></li></ul><h2 id=questions-for-jana>Questions for Jana</h2><ul><li>for <a href=/posts/kbhdiagonal_matrix/#properties-of-diagonal-matrices>diagonalizability</a>, shouldn&rsquo;t \(n\) be \(m\) on item 3?</li></ul><h2 id=interesting-factoids>Interesting Factoids</h2><p>Short!</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/34/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/33/ aria-label="Page 33" class=page-link role=button>33</a></li><li class=page-item><a href=/posts/page/34/ aria-label="Page 34" class=page-link role=button>34</a></li><li class="page-item active"><a aria-current=page aria-label="Page 35" class=page-link role=button>35</a></li><li class=page-item><a href=/posts/page/36/ aria-label="Page 36" class=page-link role=button>36</a></li><li class=page-item><a href=/posts/page/37/ aria-label="Page 37" class=page-link role=button>37</a></li><li class=page-item><a href=/posts/page/36/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>