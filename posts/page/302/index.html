<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>Posts</div></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><main><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsu_cs224n_apr302024/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhsu_cs224n_apr302024/>SU-CS224N APR302024</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=subword>Subword</h2><p>We use SUBWORD modeling modeling to deal with:</p><ol><li>combinatorial morphology (resolving word form and infinitives) &mdash; &ldquo;a single word has a million forms in Finnish&rdquo; (&ldquo;transformify&rdquo;)</li><li>misspelling</li><li>extensions/emphasis (&ldquo;gooooood vibessssss&rdquo;)</li></ol><p>You mark each actual word ending with some of combine marker.</p><p>To fix this:</p><h3 id=byte-pair-encoding--kbhbpe-dot-md><a href=/posts/kbhbpe/>Byte-Pair Encoding</a></h3><p>&ldquo;find pieces of words that are common and treat them as a vocabulary&rdquo;</p><ol><li>start with vocab containing only characters and EOS</li><li>look at the corpus, and find the most common pair of adjacent characters</li><li>replace all instances of the pair with the new subword</li><li>repeat 2-3 until vecab size is big enough</li></ol><h2 id=writing-systems>Writing Systems</h2><ul><li>phonemic (directly translating sounds, see Spanish)</li><li>fossilized phonemic (English, where sounds are whack)</li><li>syllabic/moratic (each sound syllable written down)</li><li>ideographic (syllabic, but no relation to sound instead have meaning)</li><li>a combination of the above (Japanese)</li></ul><h2 id=whole-model-pretraining>Whole-Model Pretraining</h2><ul><li>all parameters are initalized via pretraining</li><li>don&rsquo;t even bother training word vectors</li></ul><h2 id=mlm-and-ntp-are-universal-tasks>MLM and NTP are &ldquo;Universal Tasks&rdquo;</h2><p>Because in different circumstances, performing well MLM and NLP requires {local knowledge, scene representations, language, etc.}.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsu_cs224n_may022024/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhsu_cs224n_may022024/>SU-CS224N MAY022024</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=zero-shot-learning>Zero-Shot Learning</h2><p>GPT-2 is able to do many tasks with <strong>not examples</strong> + <strong>no gradient updates</strong>.</p><h2 id=instruction-fine-tuning>Instruction Fine-Tuning</h2><p>Language models, by default, are not <em>aligned</em> with user intent.</p><ol><li>collect paired examples of <strong>instruction</strong> + <strong>output</strong> across many tasks</li><li>then, evaluate on <strong>unseen tasks</strong></li></ol><p>~3 million examples &lt;&lt; n billion examples</p><p>dataset: MMLU</p><p>You can generate an <a href=#instruction-fine-tuning>Instruction Fine-Tuning</a> dataset by asking a larger model for it (see Alpaca).</p><h3 id=pros-plus-cons>Pros + Cons</h3><ul><li>simple and straightforward + generalize to unseen tasks</li><li>but, its <strong>EXPENSIVE</strong> to collect ground truth data<ul><li>ground truths maybe wrong</li><li>creative tasks may not have a correct answer</li><li>LMs penalizes all token-level mistakes equally, but some mistakes are worse than others</li><li>humans may generate suboptimal answers</li></ul></li></ul><h2 id=human-preference-modeling>Human Preference Modeling</h2><p>Imagine if we have some input \(x\), and two output trajectories, \(y_{1}\) and \(y_{2}\).</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsu_cs224n_may072024/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhsu_cs224n_may072024/>SU-CS224N MAY072024</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=benchmark-tradeoffs>Benchmark tradeoffs</h2><ul><li>baseline too high: no one can beat it</li><li>baseline too low: no differentiation</li></ul><h2 id=close-ended-evaluation>Close-ended evaluation</h2><ul><li>do standard ML (&ldquo;accuracy&rdquo;)</li><li>because there&rsquo;s one of a few known answers</li><li>types of tasks: SST, IMDP, Yelp; SNLI</li></ul><p>Most common multi-task benchmark: SuperGLUE</p><h3 id=difficult>Difficult</h3><ul><li>what metrics do you choose?</li><li>how to aggregate across metrics (average?)</li><li>label statistics</li><li>spurious correlations</li></ul><h2 id=open-ended-evaluations>Open-ended evaluations</h2><ul><li>long generations with too many correct answers (can&rsquo;t directly apply classic ML)</li><li>there are better and worse answers (relative)</li></ul><h3 id=content-overlap-metrics>Content Overlap Metrics</h3><p>compare lexical similarity between generated and gold text:</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsu_cs224n_may092024/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhsu_cs224n_may092024/>SU-CS224N MAY092024</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=floating-point>Floating Point</h2><p>4 bytes</p><p>\begin{equation}
(-1)^{B} + e^{E-127} \times \qty(1 + \sum_{i=1}^{23} b_{23-i}2^{-i})
\end{equation}</p><p>usually \(E\) is a 8 bytes, and 23 digits of \(b\).</p><p>With more \(E\), we will have more range, with more \(b\), we will have more precision.</p><h2 id=mixed-precision-training>Mixed Precision Training</h2><ol><li>copy the model in FP32</li><li>Run forward pass in FP16</li><li>Scale loss to be large enough to not be rounded away</li><li>Compute gradients in FP16</li><li>Convert the gradients onto FP32</li><li>Scale the gradients down</li><li>apply to the model</li></ol><h3 id=bfloat16>BFloat16</h3><p>To not need to scale, we can use a scheme that has less precision but the same amount of dynamic range (i.e. allocate the same \(E\), chop off \(b\)) &mdash;no need to scale, just have more dynamic range.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsu_cs224n_paper_review/"'><span class=top><h1><a class=noannot style=cursor:pointer href=https://www.jemoka.com/posts/kbhsu_cs224n_paper_review/>SU-CS224N Paper Review</a></h1><span class="modbox right">Last edited: <span class=moddate>August 8, 2025</span></span>
</span><span class=summary><h2 id=key-information>Key Information</h2><ul><li><strong>Title</strong>: Fine-Grained Language Model Detoxification with Dense, Token-Level Rewards</li><li><strong>Team Member</strong> (in 224n): Houjun Liu &lt;houjun@stanford.edu></li><li><strong>External Collaborators</strong>: Amelia Hardy &lt;ahardy@stanford.edu>, Bernard Lange &lt;blange@stanford.edu></li><li><strong>Custom Project</strong></li><li><strong>Mentor</strong>: we have no particular mentor within 224n</li><li><strong>Sharing Project</strong>: this project is shared with AA222, and is a part of a research project PI&rsquo;d by Mykel Kochenderfer &lt;mykel@stanford.edu>, of which Houjun is taking a leading role</li></ul><h2 id=research-paper-summary>Research Paper Summary</h2><table><thead><tr><th>Title</th><th>Fine-Grained Human Feedback Gives Better Rewards for Language Model Training</th></tr></thead><tbody><tr><td>Venue</td><td>NeurIPS (Spotlight)</td></tr><tr><td>Year</td><td>2023</td></tr><tr><td>URL</td><td><a href=https://arxiv.org/pdf/2306.01693>https://arxiv.org/pdf/2306.01693</a></td></tr></tbody></table><h3 id=background>Background</h3><p>Reinforcement Learning with Human Feedback (RLHF) has demonstrated superb effect for improving performance of a language model (LM) via human preference judgments of LM output desirability&ndash;reducing incidences of toxic or false generation trajectories ((<a href=#citeproc_bib_item_19>Ziegler et al. 2020</a>)). Naive application of RLHF directly has shown success in reducing the toxicity in language model outputs, yet its effects could sometimes be inconsistent without further in-context guidance of the resulting model ((<a href=#citeproc_bib_item_11>Ouyang et al. 2022</a>)).</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/301/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/300/ aria-label="Page 300" class=page-link role=button>300</a></li><li class=page-item><a href=/posts/page/301/ aria-label="Page 301" class=page-link role=button>301</a></li><li class="page-item active"><a aria-current=page aria-label="Page 302" class=page-link role=button>302</a></li><li class=page-item><a href=/posts/page/303/ aria-label="Page 303" class=page-link role=button>303</a></li><li class=page-item><a href=/posts/page/304/ aria-label="Page 304" class=page-link role=button>304</a></li><li class=page-item><a href=/posts/page/303/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/367/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>