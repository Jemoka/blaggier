<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>POMCP</title>
<meta name=description content="Previous monte-carlo tree search methods which are not competitive to PBVI, SARSOP, etc., but those are affected by close-up history.
key point: monte-cargo roll outs best-first tree search + unweighted particle filter (instead of categorical beliefs)
Background

History: a trajectory of some \(h = \{a_1, o_1, &mldr;\}\)
generative model: we perform a random sample of possible next state (weighted by the action you took, meaning an instantiation of \(s&rsquo; \sim T(\cdot | s,a)\)) and reward \(R(s,a)\) from current state
Rollout: keep sampling at each point, rolling out and calculating future reward

monte-carlo tree search

loop:

sample \(s\) from the belief distribution \(B(h)\) for each node and call that the node state
loop until we reach a leaf:

sample exploratino using UCB 1 via the belief
get observation, reward, next state


add leaf node, add node for each available action
Rollout
backpropegate the obtained value with discounts backwards via POMDP Bellman Backup



During runtime, we choose the action with the best action, prune the tree given what you observed, and do this again in a different."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>POMCP</div><span style="float:right;display:flex;align-items:center;margin-top:5px;width:100%;max-width:400px;background:#fff;border-radius:2px;border:1px solid var(--gray-2);position:relative"><i class="fa-solid fa-magnifying-glass" style=font-size:12px;color:var(--yellow-fg);margin-right:7px;margin-left:10px></i><div style=width:100%><input id=search-query-inline name=s type=text autocomplete=off placeholder="Search Knowledgebase" enterkeyhint=search></div><div id=search-result-inline style=display:none></div><script id=search-result-template type=text/x-js-template data-template=searchresult>
    <a href="${link}" class="search-link">
    <div class="search-result-item" id="search-result-item-${key}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${snippet}</div>
    </div>
    </a>
</script><script src=https://code.jquery.com/jquery-3.3.1.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js></script><script type=module>
    import { create, insertMultiple, search } from 'https://cdn.jsdelivr.net/npm/@orama/orama@latest/+esm'
    let template = $('script[data-template="searchresult"]').text().split(/\$\{(.+?)\}/g);

    function render(props) {
        return function(tok, i) { return (i % 2) ? props[tok] : tok; };
    }

    const db = create({
        schema: {
            title: 'string',
            content: 'string',
        },
    });
    $.get("https://www.jemoka.com/index.json", function(data, status){
        insertMultiple(db, data.map(x =>
            ({title: x.title, content: x.contents, link: x.permalink})));
    });
    $("#search-result-inline").attr("tabindex", "-1");
    $(document).on("click", function (e) {
    if (!$(e.target).closest("#search-query-inline, #search-result-inline").length) {
        $("#search-result-inline").hide();
    }
    });
    
    
    
    
    
    

    $("#search-query-inline").on("focus keyup", function () {
        let value = $(this).val();
        if (value.trim() == "") {
            $("#search-result-inline").html("");
            $("#search-result-inline").hide();
            return;
        }
        $("#search-result-inline").show();
        let results = search(db, {mode: "fulltext", term: value});
        let contents = results.hits.map(x => template.map(render({
            title: x.document.title,
            snippet: x.document.content.slice(0, 52),
            key: x.id,
            link: x.document.link
        })).join(''));
        $("#search-result-inline").html(contents.join("\n"));
        
    });
    if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
        $('#search-query-inline').on('focus', function(){
            
            $(this).data('fontSize', $(this).css('font-size')).css('font-size', '16px');
        }).on('blur', function(){
            
            $(this).css('font-size', $(this).data('fontSize'));
        });
    }

</script></span></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><aside id=tocbox><div id=heading style=padding-left:40px;font-weight:600;font-size:11px;color:var(--gray-3)>contents</div><div id=toc></div></aside><main><article><div style=max-width:700px><p>Previous <a href=/posts/kbhmonte_carlo_tree_search/>monte-carlo tree search</a> methods which are not competitive to <a href=/posts/kbhpoint_based_value_iteration/>PBVI</a>, <a href=/posts/kbhsarsop/>SARSOP</a>, etc., but those are affected by close-up history.</p><p><strong>key point</strong>: monte-cargo roll outs best-first tree search + unweighted particle filter (instead of categorical beliefs)</p><h2 id=background>Background</h2><ul><li>History: a trajectory of some \(h = \{a_1, o_1, &mldr;\}\)</li><li><a href=/posts/kbhonline_planning/#generative-model>generative model</a>: we perform a random sample of possible next state (weighted by the action you took, meaning an instantiation of \(s&rsquo; \sim T(\cdot | s,a)\)) and reward \(R(s,a)\) from current state</li><li>Rollout: keep sampling at each point, rolling out and calculating future reward</li></ul><h2 id=monte-carlo-tree-search--kbhmonte-carlo-tree-search-dot-md><a href=/posts/kbhmonte_carlo_tree_search/>monte-carlo tree search</a></h2><ol><li>loop:<ol><li>sample \(s\) from the belief distribution \(B(h)\) for each node and call that the node state</li><li>loop until we reach a leaf:<ol><li>sample exploratino using <a href=/posts/kbhdirected_exploration/#ucb-1>UCB 1</a> via the belief</li><li>get observation, reward, next state</li></ol></li><li>add leaf node, add node for each available action</li><li><a href=/posts/kbhrollout_with_lookahead/#rollout>Rollout</a></li><li>backpropegate the obtained value with discounts backwards via <a href=/posts/kbhvalue_iteration/#pomdp-bellman-update>POMDP Bellman Backup</a></li></ol></li></ol><p>During runtime, we choose the action with the best action, prune the tree given what you observed, and do this again in a different.</p></div></article></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>