<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>DementiaBank Acoustics Project</title>
<meta name=description content="The DementiaBank Acoustics Project is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.
This project will attempt to replicate some of the results of Wang 2019 and Martinc 2021, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to Yuan 2021 which is automated by MFA. Goal is to replicate the results of Yuan 2021/or even Martinc 2021 in a completely automated manner."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>DementiaBank Acoustics Project</div><span style="float:right;display:flex;align-items:center;margin-top:5px;width:100%;max-width:400px;background:#fff;border-radius:2px;border:1px solid var(--gray-2);position:relative"><i class="fa-solid fa-magnifying-glass" style=font-size:12px;color:var(--yellow-fg);margin-right:7px;margin-left:10px></i><div style=width:100%><input id=search-query-inline name=s type=text autocomplete=off placeholder="Search Knowledgebase" enterkeyhint=search></div><div id=search-result-inline style=display:none></div><script id=search-result-template type=text/x-js-template data-template=searchresult>
    <a href="${link}" class="search-link">
    <div class="search-result-item" id="search-result-item-${key}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${snippet}</div>
    </div>
    </a>
</script><script src=https://code.jquery.com/jquery-3.3.1.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js></script><script type=module>
    import { create, insertMultiple, search } from 'https://cdn.jsdelivr.net/npm/@orama/orama@latest/+esm'
    let template = $('script[data-template="searchresult"]').text().split(/\$\{(.+?)\}/g);

    function render(props) {
        return function(tok, i) { return (i % 2) ? props[tok] : tok; };
    }

    const db = create({
        schema: {
            title: 'string',
            content: 'string',
        },
    });
    $.get("https://www.jemoka.com/index.json", function(data, status){
        insertMultiple(db, data.map(x =>
            ({title: x.title, content: x.contents, link: x.permalink})));
    });
    $("#search-result-inline").attr("tabindex", "-1");
    $(document).on("click", function (e) {
    if (!$(e.target).closest("#search-query-inline, #search-result-inline").length) {
        $("#search-result-inline").hide();
    }
    });
    
    
    
    
    
    

    $("#search-query-inline").on("focus keyup", function () {
        let value = $(this).val();
        if (value.trim() == "") {
            $("#search-result-inline").html("");
            $("#search-result-inline").hide();
            return;
        }
        $("#search-result-inline").show();
        let results = search(db, {mode: "fulltext", term: value});
        let contents = results.hits.map(x => template.map(render({
            title: x.document.title,
            snippet: x.document.content.slice(0, 52),
            key: x.id,
            link: x.document.link
        })).join(''));
        $("#search-result-inline").html(contents.join("\n"));
        
    });
    if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
        $('#search-query-inline').on('focus', function(){
            
            $(this).data('fontSize', $(this).css('font-size')).css('font-size', '16px');
        }).on('blur', function(){
            
            $(this).css('font-size', $(this).data('fontSize'));
        });
    }

</script></span></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><aside id=tocbox><div id=heading style=padding-left:40px;font-weight:600;font-size:11px;color:var(--gray-3)>contents</div><div id=toc></div></aside><main><article><div style=max-width:700px><p>The <a href=/posts/kbhdementiabank_acoustics_project/>DementiaBank Acoustics Project</a> is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.</p><p>This project will attempt to replicate some of the results of <a href=/posts/kbhwang_2019/>Wang 2019</a> and <a href=/posts/kbhmartinc_2021/>Martinc 2021</a>, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to <a href=/posts/kbhyuan_2021/>Yuan 2021</a> which is automated by MFA. Goal is to replicate the results of <a href=/posts/kbhyuan_2021/>Yuan 2021</a>/or even <a href=/posts/kbhmartinc_2021/>Martinc 2021</a> in a completely automated manner.</p><h2 id=background-reading>Background Reading</h2><p>I first began by doing a literature survey on the <a href=/posts/kbhadress_literature_survey/>ADReSS Challenge</a> results published in the Frontiers AD special interest group issue.</p><h2 id=proposal>Proposal</h2><p>And then, we wrote a proposal: <a href=/posts/kbhdementiabank_acoustics_project_proposal/>DementiaBank Acoustics Project Proposal</a></p><h2 id=brainstoming>Brainstoming</h2><p>More notes from the meeting: <a href=/posts/kbhdementiabank_acoustics_brainstoming/>DementiaBank Acoustics Brainstoming</a></p><h2 id=protocol-notes>Protocol Notes</h2><h3 id=july-1st>July 1st</h3><ul><li>Began by moving a subsample of <a href=https://dementia.talkbank.org/access/English/Pitt.html>Pitt</a>&rsquo;s <a href=/posts/kbhctp/>Cookie Theft</a> to <code>pitt-7-1</code> in the <code>raw</code> data folder</li><li>Ran <code>flo</code> on all collected samples. Arguments used are the same as that for <a href=/posts/kbhbatchalign/>batchalign</a>, except <em>we filter out the <code>INV</code> tier</em> as we are detecting AD on patient and not investigator: so <code>flo +d +ca +t* -tINV</code></li><li>Moved all collected samples (and changed extension to .txt) to the same sub-folder, but in <code>transcripts_nodisfluency</code></li></ul><h3 id=july-2nd>July 2nd</h3><ul><li>Created a dataprep script <code>dataprep.py</code> which dumps a pickled copy of cleaned data to <code>transcripts_nodisfluency/pitt-7-1.dat</code>.</li><li>Created sliding windows of 5 pieces of dialogue concatenated, stored it in <code>transcripts_nodisfluency/pitt-7-1-windowed.dat</code></li><li>Used tencent/HuYong&rsquo;s <code>nghuyong/ernie-2.0-en</code> Ernie 2.0 model, the continuous language model from Baidu (Layer:12, Hidden:768, Heads:12)</li></ul><h3 id=july-4th>July 4th</h3><ul><li>Finalized training code. Selected base hyperparameters {bs: 8, epochs: 2, lr: 3e-3, length: 60}. Again, we are using Baidu&rsquo;s <code>nghuyong/ernie-2.0-en</code>.</li><li>Started training fastcalculator on <code>24bc812</code></li></ul><h4 id=train-faithful-frog-3>train: faithful-frog-3</h4><p>{bs: 8, epochs: 2, lr: 3e-3, length: 60, pitt-7-1-windowed.dat }</p><figure><img src=/ox-hugo/2022-07-04_19-20-13_screenshot.png></figure><ul><li>Commentary: LR could be too high, looking at the divergent loss behavior.</li><li>Decision: dropping bs to <code>4</code> and lr to <code>1e-5</code>, similar to previous transformers. Also training for 3 epochs.</li></ul><h4 id=train-revived-disco-5>train: revived-disco-5</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-1-windowed.dat }</p><figure><img src=/ox-hugo/2022-07-04_19-28-07_screenshot.png></figure><ul><li>Commentary: quintessential overfitting</li><li>Decision:<ul><li>Made the corpus bigger<ul><li>cleaned the entire <a href=https://dementia.talkbank.org/access/English/Pitt.html>Pitt</a> corpus (<code>pitt-7-4</code> in the <code>raw</code> folder) to become training data. Similar to <code>pitt-7-1</code>, ran <code>flo</code> on all collected samples; arguments used are the same as that for <a href=/posts/kbhbatchalign/>batchalign</a>, except <em>we filter out the <code>INV</code> tier</em> as we are detecting AD on patient and not investigator: so <code>flo +d +ca +t* -tINV</code>; the <code>flo</code>&rsquo;d results are in <code>transcripts_nodisfluency</code>.</li><li>the notable difference between the previous dataset <code>7-1</code> and the current one <code>7-4</code> is that the <code>7-4</code> are prepended numbered by the task (<code>cookie/100-01.cha</code> <code>> =cookie-100-01.txt</code>)</li><li>New (full) Pitt data as prepared above is ran though the dataprep script as of <code>b325514cfad79da82d7a519ed29ea19ed87b2be4</code> (difference is that empty/dummy files are ignored), and pickled at <code>transcripts_nodisfluency/pitt-7-4.dat</code> and <code>transcripts_nodisfluency/pitt-7-4-windowed.dat</code> respectively.</li><li>For new data, window size is still <code>5</code>, splitting <code>10</code> cases out for testing now instead of <code>5</code>.</li></ul></li></ul></li></ul><h4 id=train-vocal-oath-6>train: vocal-oath-6</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed.dat}</p><figure><img src=/ox-hugo/2022-07-04_20-20-01_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-04_20-35-54_screenshot.png></figure><ul><li>Commentary: high recall, low precision. Perhaps classes aren&rsquo;t balanced?<ul><li>Spoiler alert: they are not.</li><li>An inspection of data reveals that there is 3211 rows of dementia, 2397 rows of control</li></ul></li><li>Decision:<ul><li>Created <code>pitt-7-4-bal</code> and <code>pitt-7-4-windowed-bal</code> series of data based on dataprep.py on <code>703f79248a20fd7a13a5033ca2bf7f691f42c941</code>. This version force-crops to make sure that the dementia and control indicies have the exact same length for each class.</li></ul></li></ul><h4 id=train-helpful-leaf-7>train: helpful-leaf-7</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-04_21-31-19_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-04_21-35-43_screenshot.png></figure><p>Beautiful. Question now is whether or not there is data leakage/external heuristics. It is a good time to do some <a href=/posts/kbhloo/>LOOCV</a>. Getting this result without any disfluency calculations seems unlikely.</p><p>But anyways, going to discuss these results as they seem to meet results we see in <a href=/posts/kbhyuan_2021/>Yuan 2021</a>, even without top-N ensemble; though this is one trial, <a href=/posts/kbhloo/>LOOCV</a> may still show that we actually need it.</p><h3 id=july-5th>July 5th</h3><ul><li>Began the day with creating the script k-fold validation; I originally hoped to exactly replicate the procedure of <a href=/posts/kbhyuan_2021/>Yuan 2021</a> for comparability, but, not sure how they got the actual result of a min/max range with <a href=/posts/kbhloo/>LOOCV</a> on binary; therefore, we will instead create a 95% <a href=/posts/kbhconfidence_interval/>confidence interval</a> analysis via a single-variable <a href=/posts/kbht_statistics/>t test</a> on standard k-fold validation. K=50</li><li>During one-off testing, another set of hyperparameters seems to work too: {bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}. As we have not begun tuning for hyperparameters, we are just going to use this set, K=50, for the first k-fold trial.</li></ul><h4 id=k-fold-f4zvbgfdbaqvtvxemwzczd>k-fold: F4ZVbGfdBAQvtvXemWZCZD</h4><p>code: 55f77ff1dea03c3ed66967864dc52fd2c0062f23</p><figure><img src=/ox-hugo/2022-07-05_13-22-24_screenshot.png></figure><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}
K = 50</p><figure><img src=/ox-hugo/2022-07-05_14-25-26_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-05_14-26-00_screenshot.png></figure><p>It seems like the results we got is consistent and validates in a manner which we expect.</p><h3 id=july-7th>July 7th</h3><p>Yesterday was a day filled with working on <a href=/posts/kbhbatchalign/>batchalign</a>, but we are back now. Today, I aim to look into the heuristic that I identified yesterday by playing with the model, which is that it seems like the model prefers the use of long-focused sentences <em>about</em> cookies, so the heruistic its picking up is probably on-topicness.</p><p>I am going to first leverage the lovely <code>cdpierse/transformers-interpret</code> tool to help build some explainability by adding it to validate.py. Upon some human validation with random sampling, the model seem to do less well than I&rsquo;d hoped. Running a train cycle with the new results/params seen above to see if it does better.</p><h4 id=train-brisk-oath-10>train: brisk-oath-10</h4><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_11-39-18_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_11-48-40_screenshot.png></figure><ul><li>Commentary: It seems like the model is doing overall worse from validation data, but it does fairly well during test data.</li><li>Decision:<ul><li>I can fairly confidently claim that the model is just fitting on topic. As in, if the topic is about cookies (theft/taking/cookie/mother/etc.), it will be classified as control.</li><li>One thing that we can do is to claim this task as directly task-controlled: that is, include <strong>no</strong> data except cookie and control for that difference</li><li>Then, the model would&rsquo;t be able to predict the result b/c the variation in topic won&rsquo;t have influence.</li><li>This is going to be prepared in the <code>cookiepitt-7-7-bal*</code> based on <code>dataprep.py</code> in commit <code>518dec82bb961c0a8ad02e3080289b56102aa1a2</code></li></ul></li></ul><h4 id=train-super-durian-11>train: super-durian-11</h4><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, cookiepitt-7-7-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_13-51-01_screenshot.png></figure><ul><li>Commentary: the model is <em>no where near convergence</em></li><li>Decision: multiplying the LR by 10</li></ul><h4 id=train-floral-sunset-12>train: floral-sunset-12</h4><p>{bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_13-54-38_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_14-02-47_screenshot.png></figure><ul><li>Commentary: There we go. This seem to be more in line with what we see in <a href=/posts/kbhyuan_2021/>Yuan 2021</a></li><li>Decision: ok, let&rsquo;s elongate the actual content. Perhaps we can try a 7-element search instead? This is written as <code>cookiepitt-7-7-*-long</code>. Code based on <code>9e31f4bc13c4bfe193dcc049059c3d9bda46c8d0</code></li></ul><h4 id=train-sweet-plasma-13>train: sweet-plasma-13</h4><p>{bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_15-05-28_screenshot.png></figure><ul><li>Commentary: underfitting</li><li>Dropping batch size down to 64 to add more steps</li></ul><h4 id=train-smart-river-14>train: smart-river-14</h4><p>{bs: 64, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_15-13-21_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_15-20-57_screenshot.png></figure><ul><li>Commentary: this finally fits to the specifications which <a href=/posts/kbhyuan_2021/>Yuan 2021</a> have revealed</li><li>Decision: running k-fold on this architecture</li></ul><h4 id=k-fold-xgsp4fvs6scfxczkfjovq5-dot>k-fold: XgsP4FVS6ScFxCZKFJoVQ5.</h4><p>Code: 3870651ba71da8ddb3f481a7c3e046397a09d8b2</p><figure><img src=/ox-hugo/2022-07-07_15-30-07_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_16-18-44_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_16-20-23_screenshot.png></figure><h3 id=july-8th>July 8th</h3><ul><li><p>Began the day with aligning the entirety of cookie for both control and dementia, named the dataset <code>alignedpitt-7-8</code> in the RAW folder</p></li><li><p>Per what we discussed, will add [pause] as a token to the model. Then, transcript the text such that it would contain normalized values to the pauses for pauses > 0.250 seconds. Therefore, the data would look like</p><p>&ldquo;hello my name is [pause] 262 [pause] bob&rdquo;</p></li></ul><h3 id=july-9th>July 9th</h3><ul><li>Created transcript.py, which coverts the data in <code>raw</code> to <code>transcripts_pauses</code>, which contains pause values > 250 msc and prepends them with [pause] tokens</li><li>The code from above is taken from <code>check.py</code> in <a href=/posts/kbhbatchalign/>batchalign</a>, used <code>transcript.py</code> from <code>7e19a4912cf0ad5d269c139da5ce018615495ebb</code> to clean out the dataset; placed it in similar txt format to <code>alignedpitt-7-8</code></li><li>Ran dataprep with window size of 5, created <code>alignedpitt-7-8.bat</code> and <code>alignedpitt-7-8-windowed.bat</code> as the dataprep file</li><li>starting a new training run, with <code>[pause]</code> added as a new token, code <code>06846c6c95e6b1ccf17f0660c5da76aa50231567</code></li></ul><h4 id=train-golden-tree-16>train: golden-tree-16</h4><p>{bs: 64, epochs: 3, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}</p><figure><img src=/ox-hugo/2022-07-09_11-48-01_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_11-51-24_screenshot.png></figure><p>So realistically, we have the same F1 between the two, but pause encoding increased the accuracy of prediction yet dropped recall dramatically.</p><p>As a random check, let&rsquo;s find out if simple fine-tuning (only training on classifier) would work, so:</p><figure><img src=/ox-hugo/2022-07-09_12-07-31_screenshot.png></figure><h4 id=train-jumping-blaze-17>train: jumping-blaze-17</h4><p>{bs: 64, epochs: 3, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.</p><figure><img src=/ox-hugo/2022-07-09_12-09-22_screenshot.png></figure><ul><li>Commentary: we did not like. start coverging</li><li>Bumping LR by a factor of 10</li></ul><h4 id=train-vital-water-18>train: vital-water-18</h4><p>{bs: 64, epochs: 3, lr: 1e-3, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.</p><figure><img src=/ox-hugo/2022-07-09_12-11-20_screenshot.png></figure><ul><li>Commentary: barely started converging, seem to be a local</li><li>Training for 2 more epochs</li></ul><h4 id=train-fiery-smoke-19>train: fiery-smoke-19</h4><p>{bs: 64, epochs: 5, lr: 1e-3, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.</p><figure><img src=/ox-hugo/2022-07-09_12-14-14_screenshot.png></figure><ul><li>Commentary: classic overfitting</li></ul><p>At this point, unlocking the model would probably be a good bet</p><h4 id=train-leafy-deluge-20>train: leafy-deluge-20</h4><p>{bs: 64, epochs: 5, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.</p><p>Training once again with code without locking, and bump LR down</p><figure><img src=/ox-hugo/2022-07-09_13-14-39_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_13-17-36_screenshot.png></figure><ul><li>Commentary: classic the recall is slowly creeping up</li><li>Decision: let&rsquo;s go for 8 epochs</li></ul><h4 id=train-royal-pond-21>train: royal-pond-21</h4><p>{bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.</p><figure><img src=/ox-hugo/2022-07-09_13-22-40_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_13-24-01_screenshot.png></figure><p>Commentary: let&rsquo;s run k-fold now, with these settings.</p><h4 id=k-fold-qskzwfesml52ofcqgguje2-dot>k-fold: QskZWfEsML52ofcQgGujE2.</h4><figure><img src=/ox-hugo/2022-07-09_14-06-23_screenshot.png></figure><p>{bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.</p><figure><img src=/ox-hugo/2022-07-09_16-08-09_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_16-08-31_screenshot.png></figure><p>Ok, the base hypothesis from <a href=/posts/kbhyuan_2021/>Yuan 2021</a> is very much confirmed here. The same training, same content, but pause encoding is very beneficial to the quality of the results. The results that they reported contained an ensemble data, which is in the high 80s; we can now continue doing something new as <a href=/posts/kbhyuan_2021/>Yuan 2021</a>&rsquo;s conclusion is fairly achieved.</p><figure><img src=/ox-hugo/2022-07-09_16-15-07_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_18-26-57_screenshot.png></figure><p>We can probably call the replication stage done, with no dramatically better effect.</p><h3 id=july-10th>July 10th</h3><ul><li>FluCalc! Leonid&rsquo;s lovely new program can be an uberuseful feature extraction tool</li><li>Let&rsquo;s try using to build a new dataset, and network. FluCalc + Pause Encoding + Textual Data <a href=/posts/kbhfusion/#late-fusion>late fusion</a></li><li>This is becoming <code>alignedpitt-7-8-flucalc</code>. As the program is currently under heavy development to include results from <a href=/posts/kbhbatchalign/>batchalign</a>, we will specify version <code>V 09-Jul-2022 11:00</code> for now.</li><li>Done, the new data has the same i/o shape, but then has a bunch of features filtered for nulls which contains outputs from flucalc. Again, <code>alignedpitt-7-8-flucalc</code> from <code>4346fc07c4707343c507e32786b6769b6bd6fb49</code> does not take into account results from the <code>%wor</code> tier!</li></ul><h3 id=july-11th>July 11th</h3><ul><li><code>ab19abd6486884141c9ab4e4e185255a77ae833e</code> is the final-ish version of the late fusion model</li><li>We are going to use <code>alignedpitt-7-8-flucalc</code> to start training</li></ul><h4 id=train-royal-pond-21>train: royal-pond-21</h4><p>{bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-flucalc-windowed.dat}.</p><figure><img src=/ox-hugo/2022-07-11_10-15-58_screenshot.png></figure><ul><li>Commentary: overfitting</li><li>Decision, droping lr by a factor of 10, also increasing length to 70</li></ul><h4 id=train-fallen-dust-25>train: fallen-dust-25</h4><p>{bs: 64, epochs: 8, lr: 1e-5, length: 70, alignedpitt-7-8-flucalc-windowed.dat}.</p><figure><img src=/ox-hugo/2022-07-11_10-37-32_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_10-38-37_screenshot.png></figure><ul><li>Commentary: overfitting</li><li>Decision, droping lr by a factor of 10, dropping batch size to 32, training more to 10</li></ul><h4 id=train-dainty-meadow-26>train: dainty-meadow-26</h4><p>{bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}.</p><figure><img src=/ox-hugo/2022-07-11_10-45-52_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_10-46-31_screenshot.png></figure><p><strong><strong>ah</strong></strong></p><ul><li>At this point, I think it&rsquo;d be good to do some feature selection</li><li>Let&rsquo;s do a chi^2 correlation, and select 3 best features</li></ul><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>pandas</span> <span style=color:#00a8c8>as</span> <span style=color:#111>pd</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>DATA</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;/Users/houliu/Documents/Projects/DBC/data/transcripts_pauses/alignedpitt-7-8-flucalc-windowed.bat&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># read pickle</span>
</span></span><span style=display:flex><span><span style=color:#111>df</span> <span style=color:#f92672>=</span> <span style=color:#111>pd</span><span style=color:#f92672>.</span><span style=color:#111>read_pickle</span><span style=color:#111>(</span><span style=color:#111>DATA</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># test</span>
</span></span><span style=display:flex><span><span style=color:#111>test_data</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#111>[</span><span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>split</span><span style=color:#f92672>==</span><span style=color:#d88200>&#34;test&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#75715e># also, get only train data</span>
</span></span><span style=display:flex><span><span style=color:#111>df</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#111>[</span><span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>split</span><span style=color:#f92672>==</span><span style=color:#d88200>&#34;train&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#111>df</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>              target  mor_Utts  ...  split                                          utterance
</span></span><span style=display:flex><span>trial sample                    ...
</span></span><span style=display:flex><span>120-2 1049         1 -0.179084  ...  train  well the boy is getting some cookies handing o...
</span></span><span style=display:flex><span>336-1 2492         0 -0.481740  ...  train  +oh okay, the the little girl askin(g) for the...
</span></span><span style=display:flex><span>076-4 786          1 -0.179084  ...  train  well the little boy was looking at that cookie...
</span></span><span style=display:flex><span>279-0 2250         1  1.980274  ...  train  kid&#39;s stool turnin(g) [pause]540[pause] over s...
</span></span><span style=display:flex><span>014-2 151          1  0.746355  ...  train  he&#39;s fallin(g) off the chair  down here or try...
</span></span><span style=display:flex><span>...              ...       ...  ...    ...                                                ...
</span></span><span style=display:flex><span>208-0 1655         0 -0.481740  ...  train  the boy [pause]920[pause] is going after [paus...
</span></span><span style=display:flex><span>492-0 2696         1 -0.179084  ...  train  oh yes quite a_lot the kid&#39;s tryin(g) to get t...
</span></span><span style=display:flex><span>497-1 2727         1  0.129396  ...  train  what else ? &amp;uh the see the [pause]2400[pause]...
</span></span><span style=display:flex><span>175-2 1535         0  0.863668  ...  train  the window is open you can see out the curtain...
</span></span><span style=display:flex><span>279-0 2261         1  1.980274  ...  train  the other kid with [pause]610[pause] the stool...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[2848 rows x 44 columns]
</span></span></code></pre></div><p>Let&rsquo;s slice out the bits which is labels, etc.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>in_data</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>drop</span><span style=color:#111>(</span><span style=color:#111>columns</span><span style=color:#f92672>=</span><span style=color:#111>[</span><span style=color:#d88200>&#34;utterance&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;split&#34;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>in_data</span><span style=color:#f92672>.</span><span style=color:#111>columns</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Index([&#39;mor_Utts&#39;, &#39;mor_Words&#39;, &#39;mor_syllables&#39;, &#39;#_Prolongation&#39;,
</span></span><span style=display:flex><span>       &#39;%_Prolongation&#39;, &#39;#_Broken_word&#39;, &#39;%_Broken_word&#39;, &#39;#_Block&#39;,
</span></span><span style=display:flex><span>       &#39;%_Block&#39;, &#39;#_PWR&#39;, &#39;%_PWR&#39;, &#39;#_PWR-RU&#39;, &#39;%_PWR-RU&#39;, &#39;#_WWR&#39;, &#39;%_WWR&#39;,
</span></span><span style=display:flex><span>       &#39;#_mono-WWR&#39;, &#39;%_mono-WWR&#39;, &#39;#_WWR-RU&#39;, &#39;%_WWR-RU&#39;, &#39;#_mono-WWR-RU&#39;,
</span></span><span style=display:flex><span>       &#39;%_mono-WWR-RU&#39;, &#39;Mean_RU&#39;, &#39;#_Phonological_fragment&#39;,
</span></span><span style=display:flex><span>       &#39;%_Phonological_fragment&#39;, &#39;#_Phrase_repetitions&#39;,
</span></span><span style=display:flex><span>       &#39;%_Phrase_repetitions&#39;, &#39;#_Word_revisions&#39;, &#39;%_Word_revisions&#39;,
</span></span><span style=display:flex><span>       &#39;#_Phrase_revisions&#39;, &#39;%_Phrase_revisions&#39;, &#39;#_Pauses&#39;, &#39;%_Pauses&#39;,
</span></span><span style=display:flex><span>       &#39;#_Filled_pauses&#39;, &#39;%_Filled_pauses&#39;, &#39;#_TD&#39;, &#39;%_TD&#39;, &#39;#_SLD&#39;, &#39;%_SLD&#39;,
</span></span><span style=display:flex><span>       &#39;#_Total_(SLD+TD)&#39;, &#39;%_Total_(SLD+TD)&#39;, &#39;Weighted_SLD&#39;],
</span></span><span style=display:flex><span>      dtype=&#39;object&#39;)
</span></span></code></pre></div><p>And the labels:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>out_data</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#111>[</span><span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#111>out_data</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>trial  sample
</span></span><span style=display:flex><span>120-2  1049      1
</span></span><span style=display:flex><span>336-1  2492      0
</span></span><span style=display:flex><span>076-4  786       1
</span></span><span style=display:flex><span>279-0  2250      1
</span></span><span style=display:flex><span>014-2  151       1
</span></span><span style=display:flex><span>                ..
</span></span><span style=display:flex><span>208-0  1655      0
</span></span><span style=display:flex><span>492-0  2696      1
</span></span><span style=display:flex><span>497-1  2727      1
</span></span><span style=display:flex><span>175-2  1535      0
</span></span><span style=display:flex><span>279-0  2261      1
</span></span><span style=display:flex><span>Name: target, Length: 2848, dtype: int64
</span></span></code></pre></div><p>And now, let&rsquo;s select 3 best features.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>sklearn.feature_selection</span> <span style=color:#f92672>import</span> <span style=color:#111>SelectKBest</span><span style=color:#111>,</span> <span style=color:#111>f_classif</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>k_best_tool</span> <span style=color:#f92672>=</span> <span style=color:#111>SelectKBest</span><span style=color:#111>(</span><span style=color:#111>f_classif</span><span style=color:#111>,</span> <span style=color:#111>k</span><span style=color:#f92672>=</span><span style=color:#ae81ff>3</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>k_best_tool</span><span style=color:#f92672>.</span><span style=color:#111>fit</span><span style=color:#111>(</span><span style=color:#111>in_data</span><span style=color:#111>,</span> <span style=color:#111>out_data</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>best_features</span> <span style=color:#f92672>=</span> <span style=color:#111>k_best_tool</span><span style=color:#f92672>.</span><span style=color:#111>get_feature_names_out</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>best_features</span>
</span></span></code></pre></div><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>%_WWR</td><td>%_mono-WWR</td><td>%<em>Total</em>(SLD+TD)</td></tr></tbody></table><p>OD = other disfluencies; SLD = stuttering-like disfluencies; TD = total disfluencies; WWR = whole-word-repetition</p><p>ok, let&rsquo;s select those features</p><h4 id=train-visionary-plasma-27>train: visionary-plasma-27</h4><p>{bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}. Also with feature selection.</p><figure><img src=/ox-hugo/2022-07-11_11-27-49_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_11-28-11_screenshot.png></figure><p>hmmm.</p><p>I am curious if we just ran something like a decision tree, what happens.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>in_features</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>drop</span><span style=color:#111>(</span><span style=color:#111>columns</span><span style=color:#f92672>=</span><span style=color:#111>[</span><span style=color:#d88200>&#34;utterance&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;split&#34;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>test_features</span> <span style=color:#f92672>=</span> <span style=color:#111>test_data</span><span style=color:#f92672>.</span><span style=color:#111>drop</span><span style=color:#111>(</span><span style=color:#111>columns</span><span style=color:#f92672>=</span><span style=color:#111>[</span><span style=color:#d88200>&#34;utterance&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;split&#34;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>in_targets</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#111>[</span><span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#111>test_targets</span> <span style=color:#f92672>=</span> <span style=color:#111>test_data</span><span style=color:#111>[</span><span style=color:#d88200>&#34;target&#34;</span><span style=color:#111>]</span>
</span></span></code></pre></div><p>seed the classifier, and fit.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>sklearn.ensemble</span> <span style=color:#f92672>import</span> <span style=color:#111>RandomForestClassifier</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span> <span style=color:#f92672>=</span> <span style=color:#111>RandomForestClassifier</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span><span style=color:#f92672>.</span><span style=color:#111>fit</span><span style=color:#111>(</span><span style=color:#111>in_features</span><span style=color:#111>,</span> <span style=color:#111>in_targets</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span><span style=color:#f92672>.</span><span style=color:#111>score</span><span style=color:#111>(</span><span style=color:#111>test_features</span><span style=color:#111>,</span> <span style=color:#111>test_targets</span><span style=color:#111>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>0.5932203389830508
</span></span></code></pre></div><p>OK nevermind. What about SVC?</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>sklearn.svm</span> <span style=color:#f92672>import</span> <span style=color:#111>SVC</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span> <span style=color:#f92672>=</span> <span style=color:#111>SVC</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span><span style=color:#f92672>.</span><span style=color:#111>fit</span><span style=color:#111>(</span><span style=color:#111>in_features</span><span style=color:#111>,</span> <span style=color:#111>in_targets</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>clsf</span><span style=color:#f92672>.</span><span style=color:#111>score</span><span style=color:#111>(</span><span style=color:#111>test_features</span><span style=color:#111>,</span> <span style=color:#111>test_targets</span><span style=color:#111>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>0.5932203389830508
</span></span></code></pre></div><p>Turns out, deep learning still does better. I&rsquo;m thinking maybe the output is being faulty, say, for something like the loss function.</p><p>Decision: switching activation to sigmoid.</p><h4 id=train-sunny-bush-31>train: sunny-bush-31</h4><p>{bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features</p><figure><img src=/ox-hugo/2022-07-11_12-35-52_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_12-37-21_screenshot.png></figure><p>Ok let&rsquo;s think about this. Decision: added batch normalization.</p><h4 id=train-autumn-jazz-32>train: autumn-jazz-32</h4><p>{bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features</p><figure><img src=/ox-hugo/2022-07-11_12-50-10_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_12-50-56_screenshot.png></figure><p>The model maybe overfitting on some simple heuristic; some basic statistics revealed that these variables are actually quite differently distributed.</p><figure><img src=/ox-hugo/2022-07-11_13-06-06_screenshot.png></figure><p>Perhaps we should increase the complexity of the model?</p><figure><img src=/ox-hugo/2022-07-11_13-08-49_screenshot.png></figure><h4 id=train-fallen-microwave-33>train: fallen-microwave-33</h4><p>{bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features</p><p>Just to test, I am bumping the LR to 1e-5, just to see what happens. I am very confused.</p><figure><img src=/ox-hugo/2022-07-11_13-14-26_screenshot.png></figure><h4 id=train-upbeat-flower-35>train: upbeat-flower-35</h4><p>{bs: 32, epochs: 10, lr: 1e-5, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features</p><figure><img src=/ox-hugo/2022-07-11_13-21-53_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-11_13-23-35_screenshot.png></figure><p>The more we work on this, the more overfit it gets. (I FORGOT A RELUCTIFIER)</p><h4 id=a-note>a note</h4><p>{bs: 32, epochs: 10, lr: 1e-5, length: 70, alignedpitt-7-11-flucalc-windowed.dat}, selected features</p><figure><img src=/ox-hugo/2022-07-11_17-07-45_screenshot.png></figure><p>Pauses, no meta:</p><figure><img src=/ox-hugo/2022-07-11_17-09-23_screenshot.png></figure><p>Pauses, meta:</p><figure><img src=/ox-hugo/2022-07-11_17-08-41_screenshot.png></figure><p>so effectively cointoss</p><h2 id=concerns-and-questions>Concerns and Questions</h2><h3 id=july-2nd>July 2nd</h3><ul><li><code>pitt7-1/dementia/493-0</code> PAR tier &ldquo;tell me everything you see going on in that picture&rdquo; doesn&rsquo;t seem to be labeled correctly; I am guessing that&rsquo;s supposed to be INV?</li><li>Has anyone tried to include investigator/participant cross-dialogue?</li></ul><h3 id=july-4th>July 4th</h3><ul><li>Is the model overfitting on antiquated language?</li><li>Is the model overfitting on cooke-theft on-topic-ness?</li></ul><h3 id=july-11th>July 11th</h3><ul><li>LSTM only on pauses?</li></ul></div></article></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>