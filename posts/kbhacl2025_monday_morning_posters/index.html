<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>ACL2025 Monday Morning Posters</title>
<meta name=description content="ACL2025 Zhang: FaithfulRAG: Fact level conflict modeling
Key insight: RAG performance degrades wen model has context and parametric knowledge mismatch, identifying those and use three step iterative method to improve context faithfulness.
ACL2025 Ding: LLM reasoning capability via scalable question synthesis
Key insight: generate free-from questions conditioned only in BOS, then distill and DPO to get a nice question generation dataset and directly fine tune
ACL2025 Wen: synthetic data strategy on domain specific retrieval
Key insight: train your models enough to memorize the context of a specific domain and therefore be able to recall better in particular using document based IDs"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>ACL2025 Monday Morning Posters</div><span style="float:right;display:flex;align-items:center;margin-top:5px;width:100%;max-width:400px;background:#fff;border-radius:2px;border:1px solid var(--gray-2);position:relative"><i class="fa-solid fa-magnifying-glass" style=font-size:12px;color:var(--yellow-fg);margin-right:7px;margin-left:10px></i><div style=width:100%><input id=search-query-inline name=s type=text autocomplete=off placeholder="Search Knowledgebase" enterkeyhint=search></div><div id=search-result-inline style=display:none></div><script id=search-result-template type=text/x-js-template data-template=searchresult>
    <a href="${link}" class="search-link">
    <div class="search-result-item" id="search-result-item-${key}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${snippet}</div>
    </div>
    </a>
</script><script src=https://code.jquery.com/jquery-3.3.1.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js></script><script type=module>
    import { create, insertMultiple, search } from 'https://cdn.jsdelivr.net/npm/@orama/orama@latest/+esm'
    let template = $('script[data-template="searchresult"]').text().split(/\$\{(.+?)\}/g);

    function render(props) {
        return function(tok, i) { return (i % 2) ? props[tok] : tok; };
    }

    const db = create({
        schema: {
            title: 'string',
            content: 'string',
        },
    });
    $.get("https://www.jemoka.com/index.json", function(data, status){
        insertMultiple(db, data.map(x =>
            ({title: x.title, content: x.contents, link: x.permalink})));
    });
    $("#search-result-inline").attr("tabindex", "-1");
    $(document).on("click", function (e) {
    if (!$(e.target).closest("#search-query-inline, #search-result-inline").length) {
        $("#search-result-inline").hide();
    }
    });
    
    
    
    
    
    

    $("#search-query-inline").on("focus keyup", function () {
        let value = $(this).val();
        if (value.trim() == "") {
            $("#search-result-inline").html("");
            $("#search-result-inline").hide();
            return;
        }
        $("#search-result-inline").show();
        let results = search(db, {mode: "fulltext", term: value});
        let contents = results.hits.map(x => template.map(render({
            title: x.document.title,
            snippet: x.document.content.slice(0, 52),
            key: x.id,
            link: x.document.link
        })).join(''));
        $("#search-result-inline").html(contents.join("\n"));
        
    });
    if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
        $('#search-query-inline').on('focus', function(){
            
            $(this).data('fontSize', $(this).css('font-size')).css('font-size', '16px');
        }).on('blur', function(){
            
            $(this).css('font-size', $(this).data('fontSize'));
        });
    }

</script></span></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><aside id=tocbox><div id=heading style=padding-left:40px;font-weight:600;font-size:11px;color:var(--gray-3)>contents</div><div id=toc></div></aside><main><article><div style=max-width:700px><h2 id=acl2025-zhang-faithfulrag-fact-level-conflict-modeling>ACL2025 Zhang: FaithfulRAG: Fact level conflict modeling</h2><p>Key insight: RAG performance degrades wen model has context and parametric knowledge mismatch, identifying those and use three step iterative method to improve context faithfulness.</p><h2 id=acl2025-ding-llm-reasoning-capability-via-scalable-question-synthesis>ACL2025 Ding: LLM reasoning capability via scalable question synthesis</h2><p>Key insight: generate free-from questions conditioned only in BOS, then distill and DPO to get a nice question generation dataset and directly fine tune</p><h2 id=acl2025-wen-synthetic-data-strategy-on-domain-specific-retrieval>ACL2025 Wen: synthetic data strategy on domain specific retrieval</h2><p>Key insight: train your models enough to memorize the context of a specific domain and therefore be able to recall better in particular using document based IDs</p><h2 id=acl2025-xu-updating-small-kv-cache-during-longform-generation>ACL2025 Xu: updating small KV cache during longform generation</h2><p>Key insight: evict members of KV cache that has small attention scores whenever you run out</p><h2 id=acl2025-wu-batch-speculative-decoding>ACL2025 Wu: batch speculative decoding</h2><p>Key insight: generate extra draft tokens in speculative decoding, use those to fill up extra space, greedily selected tokens to re-verify</p><h2 id=acl2025-kong-segment-level-direct-preference-optimization>ACL2025 Kong: segment level direct preference optimization</h2><p>Key insight: entire 2 conversation rollout, use LLM as judge to pick out key segment, then tune in key segments. Key insight is that scores are based on entire conversation, but tuning is only on key segments.</p><h2 id=acl2025-he-idimaticity-in-word-representations>ACL2025 He: idimaticity in word representations</h2><p>Key insight: idioms are represented well in models, but if you do random word replacements, they still are represented well. Which means that mostly it is controlling for lexical overlap</p><h2 id=acl2025-hirsch-localized-attribution-queries-in-context-grounded-generation>ACL2025 Hirsch: localized attribution queries in context grounded generation</h2><p>Key insight: a new task which benchmarks attribution by first resolving coreferences and then performing context attribution</p><h2 id=acl2025-feher-retrofitting-large-language-models-with-dynamic-tokenization>ACL2025 Feher: retrofitting large language models with dynamic tokenization</h2><p>Key insight: we can tokenized data anew each batch and train a adapter</p><h2 id=acl2025-fodor-composition-and-sentence-meaning>ACL2025 Fodor: composition and sentence meaning</h2><p>Key insight: if you ever constructed a dataset that&rsquo;s lexically similar but semantically distant similarity metrics don&rsquo;t work well</p></div></article></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>