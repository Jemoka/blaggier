<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4></script><link rel=preconnect href=https://fonts.bunny.net><link href="https://fonts.bunny.net/css?family=ibm-plex-sans:300,400,400i,500,500i,600,700,700i" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>SU-CS238 SEP282023</title>
<meta name=description content="Notation
shorthand for probability
Take
\begin{equation}
P(X = 1) = \frac{1}{6}
\end{equation}
We can write this in short hand like:
\begin{equation}
P(X^{1}) = P(X=1) = \frac{1}{6}
\end{equation}
\(P\) vs \(p\)
Upper case \(P\) for probability mass function (one shot chance), lower case \(p\) for probability density functions (integral)
New Concepts

degrees of belief and describing them using the language of probability
discrete distribution and continuous distribution and joint probability distribution

important tools:

parameters of a distribution
probability density functions
cumulative distribution function
quantile function




fun probability distributions

Gaussian distribution + Truncated Gaussian distribution
uniform distribution


conditional probability and  Bayes Theorem

unique models that leverage conditional probability

conditional Gaussian models
linear gaussian model
conditional linear Gaussian models: use your big brain to add up 1) and 2), with continuous random variables \(X, Y\), and a discrete \(Z\), where \(p(x \mid y, z)\).
sigmoid model




Baysian Network and conditional independence

d seperation



Important Results / Claims

history and impact of decision making
law of total probability
fun axioms

belief axioms:

universal comparability
transitivity


probability axioms:

axiom of probability




Methods of Compressing the Parameters of a Distribution

assuming independence
using a decision tree


checking for conditional independence

Questions"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/all.css><link rel=stylesheet href=/css/page.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/typography.css><link rel=stylesheet href=/css/components.css></head><body><div class="center-clearfix p-10" style="max-width:1200px;margin:0 auto"><header class=pb-4><span class="w-full flex justify-between flex-wrap"><div style=font-weight:600;font-size:15px><a style=border:0;cursor:pointer href=/><img src=/images/Logo_Transparent.png style=width:17px;display:inline-block;margin-right:8px;transform:translateY(-2.7px)></a>SU-CS238 SEP282023</div><span style="float:right;display:flex;align-items:center;margin-top:5px;width:100%;max-width:400px;background:#fff;border-radius:2px;border:1px solid var(--gray-2);position:relative"><i class="fa-solid fa-magnifying-glass" style=font-size:12px;color:var(--yellow-fg);margin-right:7px;margin-left:10px></i><div style=width:100%><input id=search-query-inline name=s type=text autocomplete=off placeholder="Search Knowledgebase" enterkeyhint=search></div><div id=search-result-inline style=display:none></div><script id=search-result-template type=text/x-js-template data-template=searchresult>
    <a href="${link}" class="search-link">
    <div class="search-result-item" id="search-result-item-${key}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${snippet}</div>
    </div>
    </a>
</script><script src=https://code.jquery.com/jquery-3.3.1.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js></script><script type=module>
    import { create, insertMultiple, search } from 'https://cdn.jsdelivr.net/npm/@orama/orama@latest/+esm'
    let template = $('script[data-template="searchresult"]').text().split(/\$\{(.+?)\}/g);

    function render(props) {
        return function(tok, i) { return (i % 2) ? props[tok] : tok; };
    }

    const db = create({
        schema: {
            title: 'string',
            content: 'string',
        },
    });
    $.get("https://www.jemoka.com/index.json", function(data, status){
        insertMultiple(db, data.map(x =>
            ({title: x.title, content: x.contents, link: x.permalink})));
    });
    $("#search-result-inline").attr("tabindex", "-1");
    $(document).on("click", function (e) {
    if (!$(e.target).closest("#search-query-inline, #search-result-inline").length) {
        $("#search-result-inline").hide();
    }
    });
    
    
    
    
    
    

    $("#search-query-inline").on("focus keyup", function () {
        let value = $(this).val();
        if (value.trim() == "") {
            $("#search-result-inline").html("");
            $("#search-result-inline").hide();
            return;
        }
        $("#search-result-inline").show();
        let results = search(db, {mode: "fulltext", term: value});
        let contents = results.hits.map(x => template.map(render({
            title: x.document.title,
            snippet: x.document.content.slice(0, 52),
            key: x.id,
            link: x.document.link
        })).join(''));
        $("#search-result-inline").html(contents.join("\n"));
        
    });
    if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
        $('#search-query-inline').on('focus', function(){
            
            $(this).data('fontSize', $(this).css('font-size')).css('font-size', '16px');
        }).on('blur', function(){
            
            $(this).css('font-size', $(this).data('fontSize'));
        });
    }

</script></span></span><div class=w-full style="padding-bottom:4px;border-bottom:1px solid var(--gray-1);margin-top:1px"></div></header><aside id=tocbox><div id=heading style=padding-left:40px;font-weight:600;font-size:11px;color:var(--gray-3)>contents</div><div id=toc></div></aside><main><article><div style=max-width:700px><h2 id=notation>Notation</h2><h3 id=shorthand-for-probability>shorthand for probability</h3><p>Take</p><p>\begin{equation}
P(X = 1) = \frac{1}{6}
\end{equation}</p><p>We can write this in short hand like:</p><p>\begin{equation}
P(X^{1}) = P(X=1) = \frac{1}{6}
\end{equation}</p><h3 id=p-vs-p>\(P\) vs \(p\)</h3><p>Upper case \(P\) for <a href=/posts/kbhprobability_distributions/#probability-mass-function>probability mass function</a> (one shot chance), lower case \(p\) for <a href=/posts/kbhprobability_distributions/#probability-density-functions>probability density functions</a> (integral)</p><h2 id=new-concepts>New Concepts</h2><ul><li><a href=/posts/kbhprobability_theory/>degrees of belief</a> and <a href=/posts/kbhprobability_theory/#language-of-probability>describing them using the language of probability</a></li><li><a href=/posts/kbhdiscrete_distribution/>discrete distribution</a> and <a href=/posts/kbhcontinuous_distribution/>continuous distribution</a> and <a href=/posts/kbhjoint_probability_distribution/>joint probability distribution</a><ul><li><strong>important tools</strong>:<ul><li><a href=/posts/kbhparameter/>parameters of a distribution</a></li><li><a href=/posts/kbhprobability_distributions/#probability-density-functions>probability density functions</a></li><li><a href=/posts/kbhprobability_distributions/#cumulative-distribution-function>cumulative distribution function</a></li><li><a href=/posts/kbhprobability_distributions/#quantile-function>quantile function</a></li></ul></li></ul></li><li>fun <a href=/posts/kbhprobability_distributions/>probability distributions</a><ul><li><a href=/posts/kbhprobability_distributions/#gaussian-distribution>Gaussian distribution</a> + <a href=/posts/kbhprobability_distributions/#truncated-gaussian-distribution>Truncated Gaussian distribution</a></li><li><a href=/posts/kbhprobability_distributions/#uniform-distribution>uniform distribution</a></li></ul></li><li><a href=/posts/kbhprobability/#conditional-probability>conditional probability</a> and <a href=/posts/kbhbayes_theorem/>Bayes Theorem</a><ul><li>unique models that leverage <a href=/posts/kbhprobability/#conditional-probability>conditional probability</a><ol><li><a href=/posts/kbhconditional_gaussian_models/>conditional Gaussian models</a></li><li><a href=/posts/kbhlinear_gaussian_model/>linear gaussian model</a></li><li>conditional linear Gaussian models: use your big brain to add up 1) and 2), with continuous <a href=/posts/kbhrandom_variables/>random variable</a>s \(X, Y\), and a discrete \(Z\), where \(p(x \mid y, z)\).</li><li><a href=/posts/kbhsigmoid/>sigmoid model</a></li></ol></li></ul></li><li><a href=/posts/kbhbaysian_network/>Baysian Network</a> and <a href=/posts/kbhbaysian_network/#conditional-independence>conditional independence</a><ul><li><a href=/posts/kbhbaysian_network/#checking-for-conditional-independence>d seperation</a></li></ul></li></ul><h2 id=important-results-claims>Important Results / Claims</h2><ul><li><a href=/posts/kbhdecision_making_history/>history and impact of decision making</a></li><li><a href=/posts/kbhprobability/#law-of-total-probability>law of total probability</a></li><li>fun axioms<ul><li>belief axioms:<ul><li><a href=/posts/kbhprobability_theory/#universal-comparability>universal comparability</a></li><li><a href=/posts/kbhprobability_theory/#transitivity>transitivity</a></li></ul></li><li>probability axioms:<ul><li><a href=/posts/kbhprobability/#axiom-of-probability>axiom of probability</a></li></ul></li></ul></li><li><a href=/posts/kbhprobability_distributions/#methods-of-compressing-the-parameters-of-a-distribution>Methods of Compressing the Parameters of a Distribution</a><ul><li>assuming <a href=/posts/kbhprobability/#independence>independence</a></li><li>using a <a href=/posts/kbhprobability_distributions/#decision-tree>decision tree</a></li></ul></li><li><a href=/posts/kbhbaysian_network/#checking-for-conditional-independence>checking for conditional independence</a></li></ul><h2 id=questions>Questions</h2></div></article></main><footer style=margin-top:20px><p id=footer style=font-size:8px;color:var(--gray-3)>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.32.2/tocbot.min.js></script><script>tocbot.init({tocSelector:"#toc",contentSelector:".center-clearfix",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></body></html>