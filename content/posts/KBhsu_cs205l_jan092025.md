+++
title = "SU-CS205L JAN092025"
author = ["Houjun Liu"]
draft = false
+++

## Key Sequence {#key-sequence}


## Review {#review}

-   [data interpolation]({{< relref "KBhdata_interpolation.md" >}})
-   [regularization]({{< relref "KBhregularization.md" >}})


## Notation {#notation}


## New Concepts {#new-concepts}

-   [Train-Test Split]({{< relref "KBhtrain_test_split.md" >}})
-   [Robustness]({{< relref "KBhrobustness.md" >}})
    -   [well-posedness]({{< relref "KBhwell_posedness.md" >}})
-   [Numerical Stability]({{< relref "KBhnumerical_stability.md" >}})
    -   [numerically stable vector norms]({{< relref "KBhnumerical_stability.md#numerically-stable-vector-norms" >}})
    -   [numerically stable quadratic formula]({{< relref "KBhnumerical_stability.md#numerically-stable-quadratic-formula" >}})
-   [polynomial interpolation]({{< relref "KBhpolynomial_interpolation.md" >}})
    -   [Vandermonde]({{< relref "KBhpolynomial_interpolation.md" >}}) matrix + [monomial basis]({{< relref "KBhpolynomial_interpolation.md" >}})
    -   [Lagrange Basis]({{< relref "KBhpolynomial_interpolation.md#lagrange-basis" >}})
    -   [Newton Basis]({{< relref "KBhpolynomial_interpolation.md#newton-basis" >}})


## Important Results / Claims {#important-results-claims}

-   [near-singular matrix problem]({{< relref "KBhpolynomial_interpolation.md#near-singular-matrix-problem" >}})


## Questions {#questions}


## Interesting Factoids {#interesting-factoids}

-   "optimization is a wrong way to train a neural network" (because you can't hope to sample a trajectory in \\(\mathbb{R}^{n}\\) at large \\(n\\))
